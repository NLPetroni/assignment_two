{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/NLPetroni/assignment_two/blob/main/solution_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m5ldIOU6KPl4"
   },
   "source": [
    "# Imports and downloads\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zpI5pddAJRU5",
    "outputId": "1d826a3a-f480-4c32-e598-aa746a3450da"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "\n",
    "try:\n",
    "  import google.colab\n",
    "  IN_COLAB = True\n",
    "except:\n",
    "  IN_COLAB = False\n",
    "\n",
    "if not os.path.isdir('res'):\n",
    "    os.mkdir('res')\n",
    "\n",
    "if IN_COLAB:\n",
    "  %cd /content\n",
    "  !rm -rf assignment_two &> /dev/null\n",
    "  !git clone https://github.com/NLPetroni/assignment_two &> /dev/null\n",
    "  %cd assignment_two\n",
    "  sys.path.append(os.getcwd())\n",
    "  !git clone https://gitlab.com/sasso-effe/nlp-assignment-data.git &> /dev/null\n",
    "  !mv nlp-assignment-data/embedding_matrix.npy res/embedding_matrix.npy\n",
    "  !rm -rf nlp-assignment-data\n",
    "  !pip install wandb &> /dev/null\n",
    "  !pip install torchinfo &> /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "o2uzDyzCKrGy",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "from functools import reduce\n",
    "from typing import List, Callable\n",
    "import pickle\n",
    "\n",
    "import wandb\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchinfo import summary\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "\n",
    "from src import utils\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0zr8CGx9JmRN",
    "outputId": "16eb4ac3-015f-4ec2-9006-2d7e47d86e7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'Claim', 'Evidence', 'ID', 'Label'], dtype='object')\n",
      "Total rows of the train set: 121740\n",
      "Total rows of the validation set: 7165\n",
      "Total rows of the test set: 7189\n",
      "SUPPORTS    89389\n",
      "REFUTES     32351\n",
      "Name: Label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def explore():\n",
    "    utils.download_data('dataset')\n",
    "    train_set = pd.read_csv(\"dataset/train_pairs.csv\")\n",
    "    val_set = pd.read_csv(\"dataset/val_pairs.csv\")\n",
    "    test_set = pd.read_csv(\"dataset/test_pairs.csv\")\n",
    "\n",
    "    print(train_set.columns)\n",
    "    print(\"Total rows of the train set: {:d}\".format(len(train_set)))\n",
    "    print(\"Total rows of the validation set: {:d}\".format(len(val_set)))\n",
    "    print(\"Total rows of the test set: {:d}\".format(len(test_set)))\n",
    "    print(train_set['Label'].value_counts())\n",
    "explore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yBtVzSl_J0CR"
   },
   "source": [
    "# Dataset pre-processing and conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "mps78KxwJ1e6"
   },
   "outputs": [],
   "source": [
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;\\t-]')\n",
    "GOOD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "BAD_SYMBOLS_RE = re.compile('(-LRB-)|(-RRB-)|(-LSB-)|(-RSB-)')\n",
    "INSIDE_SQAURE_BRACKETS_RE = re.compile('(-LSB-).*?(-RSB-)')\n",
    "\n",
    "try:\n",
    "    STOPWORDS = set(stopwords.words('english'))\n",
    "except LookupError:\n",
    "    nltk.download('stopwords')\n",
    "    STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def remove_inside_square_brackets(text: str) -> str:\n",
    "    return INSIDE_SQAURE_BRACKETS_RE.sub('', text)\n",
    "\n",
    "def remove_bad_symbols(text: str) -> str:\n",
    "    return BAD_SYMBOLS_RE.sub('', text)\n",
    "\n",
    "def remove_final_tags(text: str) -> str:\n",
    "   return re.sub('\\.\\t.*?$', '', text) \n",
    "\n",
    "def lower(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Transforms given text to lower case.\n",
    "    Example:\n",
    "    Input: 'I really like New York city'\n",
    "    Output: 'i really like new your city'\n",
    "    \"\"\"\n",
    "\n",
    "    return text.lower()\n",
    "\n",
    "def replace_special_characters(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Replaces special characters, such as paranthesis,\n",
    "    with spacing character\n",
    "    \"\"\"\n",
    "\n",
    "    return REPLACE_BY_SPACE_RE.sub(' ', text)\n",
    "\n",
    "def replace_br(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Replaces br characters\n",
    "    \"\"\"\n",
    "\n",
    "    return text.replace('</br>', '')\n",
    "\n",
    "def filter_out_uncommon_symbols(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Removes any special character that is not in the\n",
    "    good symbols list (check regular expression)\n",
    "    \"\"\"\n",
    "\n",
    "    return GOOD_SYMBOLS_RE.sub('', text)\n",
    "\n",
    "def remove_stopwords(text: str) -> str:\n",
    "    return ' '.join([x for x in text.split() if x and x not in STOPWORDS])\n",
    "\n",
    "\n",
    "def strip_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Removes any left or right spacing (including carriage return) from text.\n",
    "    Example:\n",
    "    Input: '  This assignment is cool\\n'\n",
    "    Output: 'This assignment is cool'\n",
    "    \"\"\"\n",
    "\n",
    "    return text.strip()\n",
    "\n",
    "def split_text(text: str) -> List:\n",
    "  return text.split()\n",
    "\n",
    "PREPROCESSING_PIPELINE = [\n",
    "                          remove_inside_square_brackets,\n",
    "                          remove_bad_symbols,\n",
    "                          lower,\n",
    "                          remove_final_tags,\n",
    "                          replace_special_characters,\n",
    "                          filter_out_uncommon_symbols,\n",
    "                          strip_text,\n",
    "                          split_text\n",
    "                          ]\n",
    "\n",
    "# Anchor method\n",
    "\n",
    "def text_prepare(text: str,\n",
    "                 filter_methods: List[Callable[[str], str]] = None) -> str:\n",
    "    \"\"\"\n",
    "    Applies a list of pre-processing functions in sequence (reduce).\n",
    "    Note that the order is important here!\n",
    "    \"\"\"\n",
    "\n",
    "    filter_methods = filter_methods if filter_methods is not None else PREPROCESSING_PIPELINE\n",
    "\n",
    "    return reduce(lambda txt, f: f(txt), filter_methods, text)\n",
    "\n",
    "def full_preprocessing(dataset):\n",
    "    # In the evidences there is an id at the beginning of the sequence which is\n",
    "    # removed with the splice [:1]\n",
    "    dataset['Evidence'] = dataset['Evidence'].apply(lambda txt: text_prepare(txt)[1:])\n",
    "    dataset['Claim'] = dataset['Claim'].apply(lambda txt: text_prepare(txt))\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "kFRnAOuk2Wjb",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ePHzgALO2Wjd",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    \"\"\"Simple dataset class to use dataloaders (batching) \"\"\"\n",
    "    def __init__(self, ids, claims, evidences, labels, majority_vote=False):\n",
    "        self.majority_vote = majority_vote\n",
    "        if self.majority_vote:\n",
    "            self.ids = ids\n",
    "            self.indexes = list(set(self.ids))\n",
    "            self.majority_data = [[(claims[i], evidences[i], labels[i]) for i, id in enumerate(self.ids) if id == idx]\n",
    "                                  for idx in self.indexes]\n",
    "        else:\n",
    "            self.claims = claims\n",
    "            self.evidences = evidences\n",
    "            self.labels = torch.tensor(labels, dtype=torch.float)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.majority_vote:\n",
    "          item = self.majority_data[idx]\n",
    "        else:\n",
    "          item = self.claims[idx], self.evidences[idx], self.labels[idx]        \n",
    "        return item\n",
    "    def __len__(self):\n",
    "        return len(self.indexes) if self.majority_vote else self.claims.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "dMzmoTsXf_1_"
   },
   "outputs": [],
   "source": [
    "def to_tensor_collate(batch):\n",
    "    claims, evidences, labels = zip(*batch)\n",
    "    return torch.as_tensor(claims), None,  torch.as_tensor(evidences), None, torch.as_tensor(labels)\n",
    "\n",
    "\n",
    "def pad_batch_collate(batch):\n",
    "    \"\"\"Used by DataLoader to pad each batch independently\"\"\"\n",
    "    claims, evidences, targets = zip(*batch)\n",
    "\n",
    "    claims_lens = torch.as_tensor([len(seq) for seq in claims])\n",
    "    padded_claims = torch.nn.utils.rnn.pad_sequence([torch.as_tensor(seq) for seq in claims], \n",
    "                                                    batch_first=True, padding_value=utils.PAD_TOKEN)\n",
    "    evidences_lens = torch.as_tensor([len(seq) for seq in evidences])\n",
    "    padded_evidences = torch.nn.utils.rnn.pad_sequence([torch.as_tensor(seq) for seq in evidences], \n",
    "                                                    batch_first=True, padding_value=utils.PAD_TOKEN)\n",
    "    targets = torch.as_tensor(targets)\n",
    "\n",
    "    return padded_claims, claims_lens, padded_evidences, evidences_lens, targets\n",
    "\n",
    "\n",
    "def pad_vote_collate(batch):\n",
    "    \"\"\"\n",
    "    Collate function for the dataloader, used for majority voting evaluation.\n",
    "    Returns:\n",
    "        A list of batches, where each batch contains all the pairs claim-evidence for a single claim.\n",
    "        The list is unpacked in the evaluation method and passed batch-by-batch to the model.\n",
    "    \"\"\"\n",
    "    batch_res = []\n",
    "    \n",
    "    for elem in batch:\n",
    "        claims, evidences, targets = zip(*elem)\n",
    "        claims_lens = torch.as_tensor([len(seq) for seq in claims])\n",
    "        padded_claims = torch.nn.utils.rnn.pad_sequence([torch.as_tensor(seq) for seq in claims], \n",
    "                                                         batch_first=True, padding_value=utils.PAD_TOKEN)\n",
    "        evidences_lens = torch.as_tensor([len(seq) for seq in evidences])\n",
    "        padded_evidences = torch.nn.utils.rnn.pad_sequence([torch.as_tensor(seq) for seq in evidences], \n",
    "                                                            batch_first=True, padding_value=utils.PAD_TOKEN)\n",
    "        targets = torch.as_tensor(targets)\n",
    "        batch_res.append([padded_claims, claims_lens, padded_evidences, evidences_lens, targets])\n",
    "\n",
    "    return batch_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fo02GPAtUBlt"
   },
   "source": [
    "## Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "gbq8J24TXLdm"
   },
   "outputs": [],
   "source": [
    "def __generate_voc_and_matrix(train_set, val_set, test_set):\n",
    "  voc_evidence_train = [item for sublist in train_set['Evidence'] for item in sublist]\n",
    "  voc_claim_train = [item for sublist in train_set['Claim'] for item in sublist]\n",
    "  TRAIN_VOC = set(voc_evidence_train + voc_claim_train)\n",
    "  voc_evidence_val = [item for sublist in val_set['Evidence'] for item in sublist]\n",
    "  voc_claim_val = [item for sublist in val_set['Claim'] for item in sublist]\n",
    "  VAL_VOC = set(voc_evidence_val + voc_claim_val)\n",
    "  voc_evidence_test = [item for sublist in test_set['Evidence'] for item in sublist]\n",
    "  voc_claim_test = [item for sublist in test_set['Claim'] for item in sublist]\n",
    "  TEST_VOC = set(voc_evidence_test + voc_claim_test)\n",
    "\n",
    "  inputs = train_set['Evidence'].tolist() + train_set['Claim'].tolist()\n",
    "  glove_voc, embedding_matrix = utils.get_glove(number_token=False)\n",
    "  vocabulary, embedding_matrix = utils.add_oov(glove_voc, TRAIN_VOC, embedding_matrix, inputs)\n",
    "  inputs = val_set['Evidence'].tolist() + val_set['Claim'].tolist()\n",
    "  vocabulary, embedding_matrix = utils.add_oov(vocabulary, VAL_VOC, embedding_matrix, inputs)\n",
    "  inputs = test_set['Evidence'].tolist() + test_set['Claim'].tolist()\n",
    "  vocabulary, embedding_matrix = utils.add_oov(vocabulary, TEST_VOC, embedding_matrix, inputs)\n",
    "\n",
    "  with open(\"res/vocabulary.pkl\", \"wb\") as file:\n",
    "    pickle.dump(vocabulary, file)\n",
    "  np.save(\"res/embedding_matrix.npy\", embedding_matrix)\n",
    "  return vocabulary, embedding_matrix\n",
    "\n",
    "\n",
    "def get_voc_and_matrix(train_set, val_set, test_set):\n",
    "    if os.path.exists(\"res/vocabulary.pkl\"):\n",
    "      print('The vocabulary is already present. Loading it...', end=' ')\n",
    "      with open('res/vocabulary.pkl', 'rb') as f:\n",
    "        vocabulary = pickle.load(f)\n",
    "      print('Done!')\n",
    "      if os.path.exists(\"res/embedding_matrix.npy\"):\n",
    "        print('The embedding matrix is already present. Loading it...', end=' ')\n",
    "        embedding_matrix = np.load(\"res/embedding_matrix.npy\", )\n",
    "        print(\"Done!\")\n",
    "      else:\n",
    "        print('The embedding matrix is NOT present. You can download it from https://gitlab.com/sasso-effe/nlp-assignment-data and put it in the res folder. Alternatively you can generate a new embedding matrix, but the process is very long.\\n')\n",
    "        answer = input('Do you want to generate a new embedding matrix (and a new vocabulary)? (Y/n)')\n",
    "        answer = answer in ['Y', 'y', 'yes', 'Yes']\n",
    "        if answer:\n",
    "          vocabulary, embedding_matrix = __generate_voc_and_matrix(train_set, val_set, test_set)\n",
    "          print(\"Vocabulary and embedding matrix created! Remember to download the generated files if you are on Colab.\")\n",
    "        else:\n",
    "          raise Exception('Downaload the embedding matrix from https://gitlab.com/sasso-effe/nlp-assignment-data and rerun this cell')\n",
    "    else:\n",
    "      print(\"The vocabulary and the embedding matrix are NOT present. Creating them...\")\n",
    "      vocabulary, embedding_matrix = __generate_voc_and_matrix(train_set, val_set, test_set)\n",
    "      print(\"Vocabulary and embedding matrix created! Remember to download the generated files if you are on Colab.\")\n",
    "    return vocabulary, embedding_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "--zNevYb2Wjg",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "m1CpnhNzeDy4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize(input: List, vocabulary) -> torch.Tensor:\n",
    "  result = list(map(lambda x: vocabulary[x], input))\n",
    "  return result\n",
    "\n",
    "def detokenize(input: torch.Tensor, inverse_vocabulary) -> List:\n",
    "  result = input.tolist()\n",
    "  # FIXME sistemare computazione\n",
    "  result = list(map(lambda x: inverse_vocabulary[x], result))\n",
    "  return result\n",
    "\n",
    "def full_tokenization(data, vocabulary):\n",
    "    data['Evidence'] = data['Evidence'].map(lambda x: tokenize(x, vocabulary))\n",
    "    data['Claim'] = data['Claim'].map(lambda x: tokenize(x, vocabulary))\n",
    "    data['Label'] = data['Label'].map(lambda x: float(1.0) if x == 'SUPPORTS' else float(0.0))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "nHOZVjHYeDy5"
   },
   "source": [
    "# Putting everything together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "KVG0j-fPeDy5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def load_data(padding=False):\n",
    "    utils.download_data('dataset')\n",
    "    train_set = pd.read_csv(\"dataset/train_pairs.csv\")\n",
    "    val_set = pd.read_csv(\"dataset/val_pairs.csv\")\n",
    "    test_set = pd.read_csv(\"dataset/test_pairs.csv\")\n",
    "\n",
    "    # preprocessing\n",
    "    train_set = full_preprocessing(train_set)\n",
    "    val_set = full_preprocessing(val_set)\n",
    "    test_set = full_preprocessing(test_set)\n",
    "\n",
    "    if padding:\n",
    "        evidence_lens = [len(te) for te in train_set['Evidence']] + [len(ve) for ve in val_set['Evidence']] + [len(te) for te in test_set['Evidence']]\n",
    "        max_evidence_len = np.quantile(evidence_lens, 0.99, interpolation='nearest')\n",
    "\n",
    "        claim_lens = [len(te) for te in train_set['Claim']] + [len(ve) for ve in val_set['Claim']] + [len(te) for te in test_set['Claim']]\n",
    "        max_claim_len = np.quantile(claim_lens, 0.99, interpolation='nearest')\n",
    "\n",
    "        tr_ev_lens = train_set['Evidence'].map(lambda e: len(e))\n",
    "        tr_claim_lens = train_set['Claim'].map(lambda c: len(c))\n",
    "        train_set = train_set.drop(train_set[(tr_ev_lens >= max_evidence_len) | (tr_claim_lens >= max_claim_len)].index).reset_index()\n",
    "        va_ev_lens = val_set['Evidence'].map(lambda e: len(e))\n",
    "        va_claim_lens = val_set['Claim'].map(lambda c: len(c))\n",
    "        val_set = val_set.drop(val_set[(va_ev_lens >= max_evidence_len) | (va_claim_lens >= max_claim_len)].index).reset_index()\n",
    "        te_ev_lens = test_set['Evidence'].map(lambda e: len(e))\n",
    "        te_claim_lens = test_set['Claim'].map(lambda c: len(c))\n",
    "        test_set = test_set.drop(test_set[(te_ev_lens >= max_evidence_len) | (te_claim_lens >= max_claim_len)].index).reset_index()\n",
    "\n",
    "        train_set.loc[:, 'Evidence'] = train_set['Evidence'].map(lambda x: x + (['<PAD>'] * (max_evidence_len - len(x))))\n",
    "        val_set.loc[:, 'Evidence'] = val_set['Evidence'].map(lambda x: x + (['<PAD>'] * (max_evidence_len - len(x))))\n",
    "        test_set.loc[:, 'Evidence'] = test_set['Evidence'].map(lambda x: x + (['<PAD>'] * (max_evidence_len - len(x))))\n",
    "\n",
    "        train_set.loc[:, 'Claim'] = train_set['Claim'].map(lambda x: x + (['<PAD>'] * (max_claim_len - len(x))))\n",
    "        val_set.loc[:, 'Claim'] = val_set['Claim'].map(lambda x: x + (['<PAD>'] * (max_claim_len - len(x))))\n",
    "        test_set.loc[:, 'Claim'] = test_set['Claim'].map(lambda x: x + (['<PAD>'] * (max_claim_len - len(x))))\n",
    "\n",
    "\n",
    "    vocabulary, embedding_matrix = get_voc_and_matrix(train_set, val_set, test_set)\n",
    "\n",
    "    # tokenization\n",
    "    train_set = full_tokenization(train_set, vocabulary)\n",
    "    val_set = full_tokenization(val_set, vocabulary)\n",
    "    test_set = full_tokenization(test_set, vocabulary)\n",
    "\n",
    "    return vocabulary, embedding_matrix, (train_set, val_set, test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "84ym75Vh2Wjh"
   },
   "source": [
    "# Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "VMWeAnUSFmQn",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# lambda layers\n",
    "\n",
    "class LambdaLast(torch.nn.Module):\n",
    "    def forward(self, x, h_n):\n",
    "        # assuming bidirectional rnn, taking concatenation of last hidden states (of the last layer)\n",
    "        return torch.cat((h_n[-1], h_n[-2]), dim=1)\n",
    "\n",
    "class LambdaAvg(torch.nn.Module):\n",
    "  def forward(self, x, h_n):\n",
    "    # average of all the output features\n",
    "    return torch.mean(x, dim=1)\n",
    "\n",
    "class LambdaConcatenation(torch.nn.Module):\n",
    "  def forward(self, x, y):\n",
    "    return torch.cat((x, y), dim=1)\n",
    "\n",
    "class LambdaSum(torch.nn.Module):\n",
    "  def forward(self, x, y):\n",
    "    return x + y\n",
    "\n",
    "class LambdaMean(torch.nn.Module):\n",
    "  def forward(self, x, y):\n",
    "    return (x + y) / 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "J0Hk8G5NcuS4"
   },
   "outputs": [],
   "source": [
    "def get_binary_classifier(name:str, w_in: int, w_hidden: int, n_layers=2) -> nn.Sequential:\n",
    "    \"\"\"Gets a sequential container with a linear+relu+linear classifier\n",
    "\n",
    "    Args:\n",
    "        name: the name prefix to append to each layer in the container.\n",
    "        w_in: the number of the input features.\n",
    "        w_hidden: the number of internal weights\n",
    "\n",
    "    Returns: the created sequential.\n",
    "    \"\"\"\n",
    "    assert n_layers >= 2, f'n_layers is {n_layers}, must be >= 2'\n",
    "    container = nn.Sequential()\n",
    "    container.add_module(f'{name}_fc1', nn.Linear(in_features=w_in, out_features=w_hidden))    \n",
    "    container.add_module(f'{name}_ReLU', nn.ReLU())\n",
    "    for i in range(n_layers-2):\n",
    "      container.add_module(f'{name}_fc{i+2}', nn.Linear(in_features=w_hidden, out_features=w_hidden))\n",
    "      container.add_module(f'{name}_ReLU', nn.ReLU())\n",
    "    container.add_module(f'{name}_fc2', nn.Linear(in_features=w_hidden, out_features=1))\n",
    "    return container\n",
    "\n",
    " \n",
    "class RNNEncoder(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, num_layers, rnn_type='elman', output_fn='last', verbose=False):\n",
    "        super().__init__()\n",
    "        if verbose:\n",
    "          print('Initializing RNNEncoder ')\n",
    "        types = {'elman': nn.RNN, 'lstm': nn.LSTM, 'gru': nn.GRU}\n",
    "        output_layers = {'last': LambdaLast, 'avg': LambdaAvg}\n",
    "        try:\n",
    "          self.output_layer = output_layers[output_fn]()\n",
    "        except:\n",
    "          raise ValueError(f\"wrong type '{output_fn}', must be in {list(output_layers.keys())}\")\n",
    "\n",
    "        try:\n",
    "          rec_module = types[rnn_type]\n",
    "        except:\n",
    "          valid_types = list(types.keys())\n",
    "          raise ValueError(f\"wrong type '{rnn_type}', must be in {valid_types}\")\n",
    "        self.rec_module = rec_module(input_size=input_size, hidden_size=hidden_size,\n",
    "                                     bidirectional=True, batch_first=True,\n",
    "                                     num_layers=num_layers)\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        x = torch.nn.utils.rnn.pack_padded_sequence(x, lengths, batch_first=True, enforce_sorted=False)\n",
    "        x, h_n = self.rec_module(x)\n",
    "        if isinstance(h_n, tuple):\n",
    "            h_n, _ = h_n  # drop cell state\n",
    "        x, _ = torch.nn.utils.rnn.pad_packed_sequence(x, batch_first=True)\n",
    "        x = self.output_layer(x, h_n)\n",
    "        return x\n",
    "\n",
    "class BagOfVectorsEncoder(torch.nn.Module):\n",
    "\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "\n",
    "  def forward(self, x, lenghts):\n",
    "    # TODO: check if the mean is computed on the right axis\n",
    "    return torch.mean(x, dim=1)\n",
    "\n",
    "\n",
    "class MLPEncoder(torch.nn.Module):\n",
    "\n",
    "  def __init__(self, ws_in, w_out, layers=None, name='mlp'):\n",
    "    super().__init__()\n",
    "    self.ws_in = ws_in\n",
    "    self.name = name\n",
    "    self.__build_mlps(w_out, layers)\n",
    "\n",
    "  def forward(self, x, lenghts):\n",
    "    batch_size, max_tokens, embedding_dim = x.shape\n",
    "    in_features = max_tokens * embedding_dim\n",
    "    x = torch.reshape(x, (batch_size, in_features))\n",
    "    if in_features == self.ws_in[0]:\n",
    "        x = self.evidence_mlp(x)\n",
    "    elif in_features == self.ws_in[1]:\n",
    "        x = self.claim_mlp(x)\n",
    "    else:\n",
    "        raise ValueError(f'wrong input shape {x.shape}, must be in {self.ws_in}')\n",
    "    return x\n",
    "\n",
    "  def __build_mlps(self, w_out, layers):\n",
    "    if layers is None:\n",
    "        layers = [w_out, w_out]\n",
    "    else:\n",
    "        layers = [w_out] + layers\n",
    "\n",
    "    self.evidence_mlp = nn.Sequential()\n",
    "    self.evidence_mlp.add_module(f'{self.name}_fc1', nn.Linear(in_features=self.ws_in[0], out_features=layers[0]))\n",
    "    for i, (w_in, w_out) in enumerate(zip(layers[:-1], layers[1:])):\n",
    "      self.evidence_mlp.add_module(f'{self.name}_ReLU', nn.ReLU())\n",
    "      self.evidence_mlp.add_module(f'{self.name}_fc{i+2}', nn.Linear(in_features=w_in, out_features=w_out))\n",
    "\n",
    "    self.claim_mlp = nn.Sequential()\n",
    "    self.claim_mlp.add_module(f'{self.name}_fc1', nn.Linear(in_features=self.ws_in[1], out_features=layers[0]))\n",
    "    for i, (w_in, w_out) in enumerate(zip(layers[:-1], layers[1:])):\n",
    "      self.claim_mlp.add_module(f'{self.name}_ReLU', nn.ReLU())\n",
    "      self.claim_mlp.add_module(f'{self.name}_fc{i+2}', nn.Linear(in_features=w_in, out_features=w_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "-rpXu4uhqcnH"
   },
   "outputs": [],
   "source": [
    "class FactChecker(torch.nn.Module):\n",
    "\n",
    "  def __init__(self, embedding_matrix, encoder, merger, ws_in=None, rnn_type=None, rnn_output=None, rec_size=1, hid_size=50, n_layers_classifier=3, cosine_similarity=False):\n",
    "    \"\"\"\n",
    "      A recurrent network performing Neural Language Inference (Fact Checking).\n",
    "      Params:\n",
    "        embedding_matrix: the embedding matrix for word embedding\n",
    "        encoder: [rnn, mlp, bag], the encoder to compute the sentence embedding\n",
    "        merger: [concatenation, sum, mean], the multi-input merging strategy\n",
    "        n_layers_classifier: int, the number of layers in the classifier\n",
    "        RNNEncoder params, only relevant if encoder==rnn:\n",
    "          rnn_type: [elman, lstm, gru], the RNN architecure used in the encoder\n",
    "          rnn_output: [last, avg], the function to compute the sentence encoding from the RNN hidden states\n",
    "          rec_size: int, the number of layers in the rnn\n",
    "          hid_size: int, the hidden size of the rnn\n",
    "    \"\"\"\n",
    "    super().__init__()\n",
    "    self.hid_size = hid_size\n",
    "    self.cosine_similarity = cosine_similarity\n",
    "\n",
    "    # Word embedding\n",
    "    emb_size = embedding_matrix.shape[1]\n",
    "    self.emb_layer = nn.Embedding.from_pretrained(torch.as_tensor(embedding_matrix))\n",
    "\n",
    "    # Sentence embedding\n",
    "    if encoder == 'rnn':\n",
    "      self.encoder = RNNEncoder(emb_size, hid_size, rec_size, rnn_type=rnn_type, output_fn=rnn_output)\n",
    "    elif encoder == 'mlp':\n",
    "      self.encoder = MLPEncoder(ws_in=ws_in, w_out=100)\n",
    "    elif encoder == 'bag':\n",
    "      self.encoder = BagOfVectorsEncoder()\n",
    "    else:\n",
    "      raise ValueError(f\"Wrong encoder '{encoder}', must be in ['rnn', 'mlp', 'bag']\")\n",
    "\n",
    "    # Merging\n",
    "    merging_strategies = {\n",
    "        'concatenation': LambdaConcatenation,\n",
    "        'sum': LambdaSum,\n",
    "        'mean': LambdaMean\n",
    "    }\n",
    "    try:\n",
    "      merging_layer = merging_strategies[merger]\n",
    "    except:\n",
    "      valid_strategies = list(merging_strategies.keys())\n",
    "      raise ValueError(f\"wrong type '{merger}', must be in {valid_strategies}\")\n",
    "    self.merger = merging_layer()\n",
    "\n",
    "    # Classifier\n",
    "    classifier_in = self.hid_size * 2 if encoder=='rnn' else 100\n",
    "    if merger == 'concatenation':\n",
    "      classifier_in *= 2\n",
    "    if self.cosine_similarity:\n",
    "      classifier_in += 1\n",
    "    self.classifier = get_binary_classifier('classifier', w_in=classifier_in, w_hidden=classifier_in//2, n_layers=n_layers_classifier)\n",
    "\n",
    "  def forward(self, claim, claim_lengths, evidence, evidence_lengths, debug=False):\n",
    "    # Word embedding\n",
    "    claim = self.emb_layer(claim).float()\n",
    "    evidence = self.emb_layer(evidence).float()\n",
    "    if debug:\n",
    "      print(\"After word embedding\")\n",
    "      print(f\"\\tclaim.shape: {claim.shape}\")\n",
    "      print(f\"\\tevidence.shape: {evidence.shape}\")\n",
    "    # Sentence embedding\n",
    "    claim = self.encoder(claim, claim_lengths)\n",
    "    evidence = self.encoder(evidence, evidence_lengths)\n",
    "    if debug:\n",
    "      print(\"After phrase encoding\")\n",
    "      print(f\"\\tclaim.shape: {claim.shape}\")\n",
    "      print(f\"\\tevidence.shape: {evidence.shape}\")\n",
    "    # Merging\n",
    "    merged_data = self.merger(claim, evidence)\n",
    "    if debug:\n",
    "      print(\"After merging\")\n",
    "      print(f\"\\tmerged_data.shape: {merged_data.shape}\")\n",
    "    #Cosine Similarity\n",
    "    if self.cosine_similarity:\n",
    "      cs = torch.nn.functional.cosine_similarity(claim,evidence, dim=1)\n",
    "      cs = torch.unsqueeze(cs, dim=1)\n",
    "      merged_data = torch.cat((merged_data, cs), dim=1)\n",
    "    # Classifying\n",
    "    output = self.classifier(merged_data)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_GDv0pqw3UsB"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience, model, delta=0, path='res'):\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.model = model\n",
    "        self.path = path\n",
    "        if not os.path.isdir(self.path):\n",
    "            os.mkdir(self.path)\n",
    "        self.best_score = float('inf')\n",
    "        self.counter = 0\n",
    "    \n",
    "    def step(self, epoch, score):\n",
    "        \"\"\" Updates ES tracker after one epoch.\n",
    "            Params:\n",
    "                epoch: current epoch\n",
    "                score: validation loss\n",
    "            Returns tuple (stop, checkpoint), \n",
    "                where stop is True if early stopping has occurred and False otherwise,\n",
    "                and checkpoint is last best checkpoint\n",
    "        \"\"\"\n",
    "        if score < self.best_score:\n",
    "            # print('Validation loss decreasing, storing new checkpoint')\n",
    "            self.best_score = score\n",
    "            self.counter = 0\n",
    "            checkpoint = {'model': self.model.state_dict(), 'epoch': epoch}\n",
    "            torch.save(checkpoint, 'res/checkpoint.pth')\n",
    "            return False, checkpoint\n",
    "        elif abs(score - self.best_score) > self.delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                print(f'Early stopping occured at epoch {epoch} with patience {self.patience}')\n",
    "                checkpoint = torch.load('res/checkpoint.pth', map_location='cpu')\n",
    "                return True, checkpoint\n",
    "            if self.counter == (self.patience//2):\n",
    "                print(f'Validation loss increasing for {self.counter} epochs')\n",
    "        return False, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "OWtu6Umy3UPr"
   },
   "outputs": [],
   "source": [
    "def training_step(model, optimizer, loss_fn, data_loader, device):\n",
    "  model.train()\n",
    "  log_dict = {'train/loss': [], 'train/accuracy': [], 'train/precision': [], 'train/recall': [], 'train/f1': []}\n",
    "  for (claims, cl_lengths, evidences, ev_lengths, labels) in data_loader:\n",
    "    # forward\n",
    "    claims = claims.to(device) \n",
    "    evidences = evidences.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    outputs = model(claims, cl_lengths, evidences, ev_lengths)\n",
    "    outputs = outputs.view(outputs.size(0))\n",
    "    loss = loss_fn(outputs, labels)\n",
    "    loss_value = loss.item()\n",
    "\n",
    "    if not math.isfinite(loss_value):\n",
    "      print(f\"Loss is {loss_value}, stopping training\")\n",
    "      exit(1)\n",
    "\n",
    "    # backward\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        preds = torch.sigmoid(outputs).round()\n",
    "        labels, preds = labels.cpu().numpy(), preds.cpu().numpy()\n",
    "        acc = ((labels == preds).sum() / labels.size).item()\n",
    "        prec = precision_score(labels, preds)\n",
    "        rec = recall_score(labels, preds)\n",
    "        f1 = f1_score(labels, preds)\n",
    "\n",
    "    log_dict['train/loss'].append(loss_value)\n",
    "    log_dict['train/accuracy'].append(acc)\n",
    "    log_dict['train/precision'].append(prec)\n",
    "    log_dict['train/recall'].append(rec)\n",
    "    log_dict['train/f1'].append(f1)\n",
    "\n",
    "  return log_dict\n",
    "\n",
    "\n",
    "def evaluate(model, loss_fn, data_loader, device):\n",
    "  \"\"\"\n",
    "    Evaluate model on the given dataloader.\n",
    "    Parameters:\n",
    "      model: torch.nn.Module to evaluate\n",
    "      loss_fn: torch.nn criterion to use to compute loss, given outputs and targets\n",
    "      data_loader: torch.utils.data.DataLoader\n",
    "      device: torch.device where evaluation is performed\n",
    "    Returns log dict {'valid/loss' : mean loss, 'valid/{metric}': mean metric}\n",
    "  \"\"\"\n",
    "  model.eval()\n",
    "  assert len(data_loader) == 1 # must be a single batch\n",
    "  split = 'valid' # TODO implement for test set\n",
    "\n",
    "  with torch.no_grad():\n",
    "    data = next(iter(data_loader))\n",
    "\n",
    "    # Variables for majority voting\n",
    "    vote_labels = []\n",
    "    vote_preds = []\n",
    "    # Variable for standard\n",
    "    loss_values = []\n",
    "    std_labels = []\n",
    "    std_preds = []\n",
    "    for claims, cl_lengths, evidences, ev_lengths, labels in data:\n",
    "      claims = claims.to(device)\n",
    "      evidences = evidences.to(device)\n",
    "      labels = labels.to(device)\n",
    "      outputs = model(claims, cl_lengths, evidences, ev_lengths)\n",
    "      outputs = outputs.view(outputs.size(0))\n",
    "      preds = torch.sigmoid(outputs).round()\n",
    "      loss_values.append(loss_fn(outputs, labels).cpu().numpy())\n",
    "      labels = list(labels.cpu())\n",
    "      preds = list(preds.cpu())\n",
    "      # Majority voting\n",
    "      true_label = np.mean(labels).round()\n",
    "      predicted_label = np.mean(preds).round()\n",
    "      vote_labels.append(true_label)\n",
    "      vote_preds.append(predicted_label)\n",
    "      # Standard\n",
    "      std_labels += labels\n",
    "      std_preds += preds\n",
    "    # Majority voting\n",
    "    vote_acc = accuracy_score(vote_labels, vote_preds)\n",
    "    vote_prec = precision_score(vote_labels, vote_preds)\n",
    "    vote_rec = recall_score(vote_labels, vote_preds)\n",
    "    vote_f1 = f1_score(vote_labels, vote_preds)\n",
    "    # Standard\n",
    "    acc = accuracy_score(std_labels, std_preds)\n",
    "    prec = precision_score(std_labels, std_preds)\n",
    "    rec = recall_score(std_labels, std_preds)\n",
    "    f1 = f1_score(std_labels, std_preds)\n",
    "  log_dict = {f'{split}/loss': np.mean(np.concatenate(loss_values)),\n",
    "              f'{split}/accuracy': acc,\n",
    "              f'{split}/precision': prec,\n",
    "              f'{split}/recall': rec,\n",
    "              f'{split}/f1': f1,\n",
    "              f'{split}/vote_accuracy': vote_acc,\n",
    "              f'{split}/vote_precision': vote_prec,\n",
    "              f'{split}/vote_recall': vote_rec,\n",
    "              f'{split}/vote_f1': vote_f1}\n",
    "  return log_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "em6r40Wq7NWn"
   },
   "outputs": [],
   "source": [
    "DEFAULT_PARAMS = {\n",
    "          'encoder': 'rnn',\n",
    "          'merger': 'concatenation',\n",
    "          'rnn_type': 'elman',\n",
    "          'rnn_output': 'last',\n",
    "          'rec_size': 1,\n",
    "          'hid_size': 50,\n",
    "          'cosine_similarity': False\n",
    "      }\n",
    "\n",
    "def fix_random(seed):\n",
    "    \"\"\" Fix all the possible sources of randomness\n",
    "        Params:\n",
    "            seed: the seed to use\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "def train(optimizer, lr, device, n_epochs, verbose, batch_size, test=False, tags=None, seed=42, **model_params):\n",
    "  fix_random(seed)\n",
    "  model_params = {**DEFAULT_PARAMS, **model_params}\n",
    "  cfg_dict = {'epochs': n_epochs, 'batch_size': batch_size, 'optimizer': optimizer, 'lr': lr, 'params': model_params}\n",
    "\n",
    "  wandb.login(key=utils.get_wandbkey())\n",
    "  run = wandb.init(project=\"assignment-two\", entity=\"nlpetroni\", reinit=True, config=cfg_dict, tags=tags)\n",
    "  wandb.define_metric(\"train_step\")\n",
    "  wandb.define_metric(\"epoch\")\n",
    "  wandb.define_metric('train/loss', step_metric=\"train_step\", summary=\"min\")\n",
    "  wandb.define_metric(\"train/accuracy\", step_metric=\"train_step\", summary=\"max\")\n",
    "  wandb.define_metric(\"valid/loss\", step_metric=\"epoch\", summary=\"min\")\n",
    "  wandb.define_metric(\"valid/accuracy\", step_metric=\"epoch\", summary=\"max\")\n",
    "  wandb.define_metric(\"valid/precision\", step_metric=\"epoch\", summary=\"max\")\n",
    "  wandb.define_metric(\"valid/recall\", step_metric=\"epoch\", summary=\"max\")\n",
    "  wandb.define_metric(\"valid/f1\", step_metric=\"epoch\", summary=\"max\")\n",
    "  wandb.define_metric(\"valid/vote_accuracy\", step_metric=\"epoch\", summary=\"max\")\n",
    "  wandb.define_metric(\"valid/vote_precision\", step_metric=\"epoch\", summary=\"max\")\n",
    "  wandb.define_metric(\"valid/vote_recall\", step_metric=\"epoch\", summary=\"max\")\n",
    "  wandb.define_metric(\"valid/vote_f1\", step_metric=\"epoch\", summary=\"max\")\n",
    "\n",
    "  if model_params['encoder'] == 'mlp':\n",
    "      # with MLP encoder, every sequence must have the same length, thus we must pad at the dataset level\n",
    "      padding = True\n",
    "      collate_fn = to_tensor_collate\n",
    "  else:\n",
    "      # with other encoders, pad each batch independently\n",
    "      padding = False\n",
    "      collate_fn = pad_batch_collate\n",
    "\n",
    "  vocabulary, embedding_matrix, dataset = load_data(padding=padding)\n",
    "  train_set, valid_set, test_set = dataset\n",
    "  train_ds = Dataset(train_set['ID'], train_set['Claim'], train_set['Evidence'], train_set['Label'])\n",
    "  valid_ds = Dataset(valid_set['ID'], valid_set['Claim'], valid_set['Evidence'], valid_set['Label'], majority_vote=True)\n",
    "  test_ds = Dataset(test_set['ID'], test_set['Claim'], test_set['Evidence'], test_set['Label'], majority_vote=True)\n",
    "  train_dl = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, collate_fn=collate_fn, shuffle=True)\n",
    "  valid_dl = torch.utils.data.DataLoader(valid_ds, batch_size=len(valid_ds), collate_fn=pad_vote_collate)\n",
    "  test_dl = torch.utils.data.DataLoader(test_ds, batch_size=len(test_ds), collate_fn=pad_vote_collate)\n",
    "  if model_params['encoder'] == 'mlp':\n",
    "    model_params['ws_in'] = (len(train_set.loc[0, 'Evidence'] * embedding_matrix.shape[1]), len(train_set.loc[0, 'Claim'] * embedding_matrix.shape[1]))\n",
    "\n",
    "  model = FactChecker(embedding_matrix, **model_params)\n",
    "  model.to(device)\n",
    "  wandb.watch(model, log_graph=True)\n",
    "  if verbose:\n",
    "    print(summary(model))\n",
    "\n",
    "  params = [p for p in model.parameters() if p.requires_grad]\n",
    "  if optimizer == 'rmsprop':\n",
    "    optimizer = torch.optim.RMSprop(params, lr=lr, alpha=0.99, momentum=0.5, weight_decay=0)\n",
    "  elif optimizer == 'adam':\n",
    "    optimizer = torch.optim.Adam(params, lr=lr, betas=(0.9, 0.999), weight_decay=0)\n",
    "  else:\n",
    "    raise ValueError(f'wrong optim {optimizer}, either rmsprop or adam')\n",
    "\n",
    "  loss = nn.BCEWithLogitsLoss()\n",
    "  valid_loss = nn.BCEWithLogitsLoss(reduction='none')\n",
    "  train_step = 0\n",
    "  print('STARTING TRAINING')\n",
    "  print('Evaluation metrics are computed on validation set\\n')\n",
    "  print(f'EPOCHS | TRAIN LOSS | VALID LOSS | ACCURACY | PRECISION | RECALL | {\"F1\":^5} | V_ACC | V_PREC | V_REC | V_F1')\n",
    "  es_tracker = EarlyStopping(20, model)\n",
    "  epoch = 0\n",
    "  early_stopped = False\n",
    "  while epoch < n_epochs and not early_stopped:\n",
    "    log_dict = training_step(model, optimizer, loss, train_dl, device)\n",
    "    if not test:\n",
    "      log_dict.update(evaluate(model, valid_loss, valid_dl, device))\n",
    "      early_stopped, checkpoint = es_tracker.step(epoch, log_dict['valid/loss'])\n",
    "      if early_stopped:\n",
    "                model.load_state_dict(checkpoint['model'])\n",
    "      for batch_loss, batch_acc, batch_f1 in zip(log_dict['train/loss'], log_dict['train/accuracy'], log_dict['train/f1']):\n",
    "        wandb.log({'train_step': train_step, 'epoch': epoch, 'train/loss': batch_loss, 'train/accuracy': batch_acc,\n",
    "                   'train/f1': batch_f1})\n",
    "        train_step += 1\n",
    "      wandb.log({'epoch': epoch, 'valid/loss': log_dict['valid/loss'],\n",
    "                 'valid/accuracy': log_dict['valid/accuracy'],\n",
    "                 'valid/precision': log_dict['valid/precision'],\n",
    "                 'valid/recall': log_dict['valid/recall'],\n",
    "                 'valid/f1': log_dict['valid/f1'],\n",
    "                 'valid/vote_accuracy': log_dict['valid/vote_accuracy'],\n",
    "                 'valid/vote_precision': log_dict['valid/vote_precision'],\n",
    "                 'valid/vote_recall': log_dict['valid/vote_recall'],\n",
    "                 'valid/vote_f1': log_dict['valid/vote_f1']})\n",
    "      if epoch % 10 == 0:\n",
    "        print(f'[{epoch:02d}/{n_epochs:02d}]| {np.mean(log_dict[\"train/loss\"]):10.3f} | {log_dict[\"valid/loss\"]:10.3f} | {log_dict[\"valid/accuracy\"]:8.3f} | {log_dict[\"valid/precision\"]:9.3f} | {log_dict[\"valid/recall\"]:6.3f} | {log_dict[\"valid/f1\"]:4.3f} | {log_dict[\"valid/vote_accuracy\"]:5.3f} | {log_dict[\"valid/vote_precision\"]:6.3f} | {log_dict[\"valid/vote_recall\"]:5.3f} | {log_dict[\"valid/vote_f1\"]:4.3f}')\n",
    "      epoch += 1\n",
    "  if test:\n",
    "    log_dict = evaluate(model, loss, test_dl, device)\n",
    "    wandb.log()\n",
    "\n",
    "  run.finish()\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "z18L9MxcgiE0"
   },
   "outputs": [],
   "source": [
    "def GridSearch(parameters, optimizer_name='adam', device=None, verbose=True):\n",
    "  for rnn_type in parameters['rnn_type']:\n",
    "    for lr in parameters['lr']:\n",
    "      for batch_size in parameters['batch_size']:\n",
    "        for num_layer_class in parameters['num_layer_class']:\n",
    "          for num_layer_rnn in parameters['num_layer_rnn']:\n",
    "            train(optimizer_name=optimizer_name, lr=lr, device=device, n_epochs=20, verbose=verbose, batch_size=batch_size,\n",
    "                encoder='rnn', merger='concatenation', rnn_type=rnn_type, rnn_output='last', hid_size=50 , n_layers_classifier=num_layer_class, rec_size=num_layer_rnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "akZiNIWqeDzB"
   },
   "source": [
    "# Hyperparameters tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "TzJjmqcSeDzB"
   },
   "source": [
    "## Sentence encoding\n",
    "### Last state of a RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "QAdfhdhPeDzC",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "out_dir = './models'\n",
    "if not os.path.isdir(out_dir):\n",
    "    os.mkdir(out_dir)\n",
    "lr = 1e-4\n",
    "epochs = 50\n",
    "batch_size = 512\n",
    "rec_size = 2\n",
    "hid_size = 64\n",
    "opt = 'rmsprop'\n",
    "tag = 'encoding choice'\n",
    "verbose = False\n",
    "cosine_similarity = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mdiegochine\u001B[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m If you're specifying your api key in code, ensure this code is not shared publically.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Appending key for api.wandb.ai to your netrc file: /home/diego/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                    Syncing run <strong><a href=\"https://wandb.ai/nlpetroni/assignment-two/runs/30g28dhl\" target=\"_blank\">pious-donkey-413</a></strong> to <a href=\"https://wandb.ai/nlpetroni/assignment-two\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n\n                "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vocabulary is already present. Loading it... Done!\n",
      "The embedding matrix is already present. Loading it... Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING TRAINING\n",
      "Evaluation metrics are computed on validation set\n",
      "\n",
      "EPOCHS | TRAIN LOSS | VALID LOSS | ACCURACY | PRECISION | RECALL |  F1   | V_ACC | V_PREC | V_REC | V_F1\n",
      "[00/50]|      0.493 |      0.693 |    0.621 |     0.574 |  0.958 | 0.718 | 0.621 |  0.572 | 0.956 | 0.716\n",
      "[10/50]|      0.372 |      0.585 |    0.701 |     0.635 |  0.960 | 0.764 | 0.700 |  0.632 | 0.958 | 0.762\n",
      "[20/50]|      0.338 |      0.615 |    0.710 |     0.640 |  0.970 | 0.771 | 0.709 |  0.638 | 0.969 | 0.769\n",
      "[30/50]|      0.310 |      0.621 |    0.723 |     0.655 |  0.951 | 0.776 | 0.723 |  0.654 | 0.949 | 0.774\n",
      "Validation loss increasing for 10 epochs\n",
      "[40/50]|      0.285 |      0.569 |    0.736 |     0.679 |  0.902 | 0.775 | 0.736 |  0.678 | 0.897 | 0.772\n",
      "Early stopping occured at epoch 43 with patience 20\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<br/>Waiting for W&B process to finish, PID 12463... <strong style=\"color:green\">(success).</strong>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3f25ff5077554461bba5544a48a401a0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\">\n<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>train/accuracy</td><td></td></tr><tr><td>train/f1</td><td></td></tr><tr><td>train/loss</td><td></td></tr><tr><td>train_step</td><td></td></tr><tr><td>valid/accuracy</td><td></td></tr><tr><td>valid/f1</td><td></td></tr><tr><td>valid/loss</td><td></td></tr><tr><td>valid/precision</td><td></td></tr><tr><td>valid/recall</td><td></td></tr><tr><td>valid/vote_accuracy</td><td></td></tr><tr><td>valid/vote_f1</td><td></td></tr><tr><td>valid/vote_precision</td><td></td></tr><tr><td>valid/vote_recall</td><td></td></tr></table><br/></div><div class=\"wandb-col\">\n<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>43</td></tr><tr><td>train/f1</td><td>0.91582</td></tr><tr><td>train_step</td><td>10471</td></tr></table>\n</div></div>\nSynced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)\n<br/>Synced <strong style=\"color:#cdcd00\">pious-donkey-413</strong>: <a href=\"https://wandb.ai/nlpetroni/assignment-two/runs/30g28dhl\" target=\"_blank\">https://wandb.ai/nlpetroni/assignment-two/runs/30g28dhl</a><br/>\nFind logs at: <code>./wandb/run-20211218_234918-30g28dhl/logs</code><br/>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "FactChecker(\n  (emb_layer): Embedding(403484, 100)\n  (encoder): RNNEncoder(\n    (output_layer): LambdaLast()\n    (rec_module): RNN(100, 64, num_layers=2, batch_first=True, bidirectional=True)\n  )\n  (merger): LambdaConcatenation()\n  (classifier): Sequential(\n    (classifier_fc1): Linear(in_features=256, out_features=128, bias=True)\n    (classifier_ReLU): ReLU()\n    (classifier_fc2): Linear(in_features=128, out_features=1, bias=True)\n  )\n)"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# elman\n",
    "train(optimizer=opt, lr=lr, device=device, n_epochs=epochs, verbose=verbose, tags=[tag, 'elman_last'],\n",
    "    batch_size=batch_size, encoder='rnn', merger='concatenation', rnn_type='elman',\n",
    "    rnn_output='last', rec_size=rec_size, hid_size=hid_size, cosine_similarity=cosine_similarity)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m If you're specifying your api key in code, ensure this code is not shared publically.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Appending key for api.wandb.ai to your netrc file: /home/diego/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                    Syncing run <strong><a href=\"https://wandb.ai/nlpetroni/assignment-two/runs/20zxtbpo\" target=\"_blank\">sleek-snow-414</a></strong> to <a href=\"https://wandb.ai/nlpetroni/assignment-two\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n\n                "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vocabulary is already present. Loading it... Done!\n",
      "The embedding matrix is already present. Loading it... Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
      "/home/diego/miniconda3/envs/nlp/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING TRAINING\n",
      "Evaluation metrics are computed on validation set\n",
      "\n",
      "EPOCHS | TRAIN LOSS | VALID LOSS | ACCURACY | PRECISION | RECALL |  F1   | V_ACC | V_PREC | V_REC | V_F1\n",
      "[00/50]|      0.516 |      0.683 |    0.632 |     0.583 |  0.951 | 0.723 | 0.632 |  0.581 | 0.949 | 0.721\n",
      "[10/50]|      0.360 |      0.591 |    0.710 |     0.641 |  0.964 | 0.770 | 0.709 |  0.639 | 0.962 | 0.767\n",
      "[20/50]|      0.325 |      0.541 |    0.732 |     0.669 |  0.928 | 0.777 | 0.730 |  0.666 | 0.925 | 0.774\n",
      "[30/50]|      0.298 |      0.568 |    0.736 |     0.671 |  0.933 | 0.781 | 0.735 |  0.669 | 0.929 | 0.778\n",
      "Validation loss increasing for 10 epochs\n",
      "[40/50]|      0.272 |      0.566 |    0.743 |     0.686 |  0.906 | 0.780 | 0.743 |  0.685 | 0.901 | 0.778\n",
      "Early stopping occured at epoch 42 with patience 20\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<br/>Waiting for W&B process to finish, PID 12635... <strong style=\"color:green\">(success).</strong>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f3b7640c45b342389c7329fe2064890d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\">\n<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>train/accuracy</td><td></td></tr><tr><td>train/f1</td><td></td></tr><tr><td>train/loss</td><td></td></tr><tr><td>train_step</td><td></td></tr><tr><td>valid/accuracy</td><td></td></tr><tr><td>valid/f1</td><td></td></tr><tr><td>valid/loss</td><td></td></tr><tr><td>valid/precision</td><td></td></tr><tr><td>valid/recall</td><td></td></tr><tr><td>valid/vote_accuracy</td><td></td></tr><tr><td>valid/vote_f1</td><td></td></tr><tr><td>valid/vote_precision</td><td></td></tr><tr><td>valid/vote_recall</td><td></td></tr></table><br/></div><div class=\"wandb-col\">\n<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>42</td></tr><tr><td>train/f1</td><td>0.91246</td></tr><tr><td>train_step</td><td>10233</td></tr></table>\n</div></div>\nSynced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)\n<br/>Synced <strong style=\"color:#cdcd00\">sleek-snow-414</strong>: <a href=\"https://wandb.ai/nlpetroni/assignment-two/runs/20zxtbpo\" target=\"_blank\">https://wandb.ai/nlpetroni/assignment-two/runs/20zxtbpo</a><br/>\nFind logs at: <code>./wandb/run-20211219_000950-20zxtbpo/logs</code><br/>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "FactChecker(\n  (emb_layer): Embedding(403484, 100)\n  (encoder): RNNEncoder(\n    (output_layer): LambdaLast()\n    (rec_module): LSTM(100, 64, num_layers=2, batch_first=True, bidirectional=True)\n  )\n  (merger): LambdaConcatenation()\n  (classifier): Sequential(\n    (classifier_fc1): Linear(in_features=256, out_features=128, bias=True)\n    (classifier_ReLU): ReLU()\n    (classifier_fc2): Linear(in_features=128, out_features=1, bias=True)\n  )\n)"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lstm\n",
    "train(optimizer=opt, lr=lr, device=device, n_epochs=epochs, verbose=verbose, tags=[tag, 'lstm_last'],\n",
    "    batch_size=batch_size, encoder='rnn', merger='concatenation', rnn_type='lstm',\n",
    "    rnn_output='last', rec_size=rec_size, hid_size=hid_size, cosine_similarity=cosine_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "_d9YmAkseDzD",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m If you're specifying your api key in code, ensure this code is not shared publically.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Appending key for api.wandb.ai to your netrc file: /home/diego/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                    Syncing run <strong><a href=\"https://wandb.ai/nlpetroni/assignment-two/runs/3nifwyuy\" target=\"_blank\">dry-haze-415</a></strong> to <a href=\"https://wandb.ai/nlpetroni/assignment-two\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n\n                "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vocabulary is already present. Loading it... Done!\n",
      "The embedding matrix is already present. Loading it... Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING TRAINING\n",
      "Evaluation metrics are computed on validation set\n",
      "\n",
      "EPOCHS | TRAIN LOSS | VALID LOSS | ACCURACY | PRECISION | RECALL |  F1   | V_ACC | V_PREC | V_REC | V_F1\n",
      "[00/50]|      0.499 |      0.652 |    0.654 |     0.599 |  0.947 | 0.734 | 0.653 |  0.597 | 0.945 | 0.731\n",
      "[10/50]|      0.355 |      0.524 |    0.727 |     0.659 |  0.950 | 0.778 | 0.726 |  0.656 | 0.948 | 0.775\n",
      "[20/50]|      0.322 |      0.527 |    0.739 |     0.671 |  0.946 | 0.785 | 0.737 |  0.667 | 0.943 | 0.782\n",
      "[30/50]|      0.296 |      0.553 |    0.742 |     0.674 |  0.944 | 0.786 | 0.741 |  0.672 | 0.942 | 0.784\n",
      "Validation loss increasing for 10 epochs\n",
      "[40/50]|      0.273 |      0.561 |    0.747 |     0.681 |  0.937 | 0.789 | 0.747 |  0.679 | 0.934 | 0.786\n",
      "Early stopping occured at epoch 49 with patience 20\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<br/>Waiting for W&B process to finish, PID 12728... <strong style=\"color:green\">(success).</strong>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bbd355a46e9f4553aa9a6a5021b585b5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\">\n<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>train/accuracy</td><td></td></tr><tr><td>train/f1</td><td></td></tr><tr><td>train/loss</td><td></td></tr><tr><td>train_step</td><td></td></tr><tr><td>valid/accuracy</td><td></td></tr><tr><td>valid/f1</td><td></td></tr><tr><td>valid/loss</td><td></td></tr><tr><td>valid/precision</td><td></td></tr><tr><td>valid/recall</td><td></td></tr><tr><td>valid/vote_accuracy</td><td></td></tr><tr><td>valid/vote_f1</td><td></td></tr><tr><td>valid/vote_precision</td><td></td></tr><tr><td>valid/vote_recall</td><td></td></tr></table><br/></div><div class=\"wandb-col\">\n<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>train/f1</td><td>0.93</td></tr><tr><td>train_step</td><td>11899</td></tr></table>\n</div></div>\nSynced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)\n<br/>Synced <strong style=\"color:#cdcd00\">dry-haze-415</strong>: <a href=\"https://wandb.ai/nlpetroni/assignment-two/runs/3nifwyuy\" target=\"_blank\">https://wandb.ai/nlpetroni/assignment-two/runs/3nifwyuy</a><br/>\nFind logs at: <code>./wandb/run-20211219_003346-3nifwyuy/logs</code><br/>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "FactChecker(\n  (emb_layer): Embedding(403484, 100)\n  (encoder): RNNEncoder(\n    (output_layer): LambdaLast()\n    (rec_module): GRU(100, 64, num_layers=2, batch_first=True, bidirectional=True)\n  )\n  (merger): LambdaConcatenation()\n  (classifier): Sequential(\n    (classifier_fc1): Linear(in_features=256, out_features=128, bias=True)\n    (classifier_ReLU): ReLU()\n    (classifier_fc2): Linear(in_features=128, out_features=1, bias=True)\n  )\n)"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gru\n",
    "train(optimizer=opt, lr=lr, device=device, n_epochs=epochs, verbose=verbose, tags=[tag, 'gru_last'],\n",
    "    batch_size=batch_size, encoder='rnn', merger='concatenation', rnn_type='gru',\n",
    "    rnn_output='last', rec_size=rec_size, hid_size=hid_size, cosine_similarity=cosine_similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "CGR2DD7veDzF"
   },
   "source": [
    "### Average of all the output states of a RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "18d705d6f41a4cc4afc7e112598c0dc7"
     ]
    },
    "id": "uBAiGI3PeDzF",
    "outputId": "f0f7e32b-7cee-444e-a6aa-19ad36e03f2a",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m If you're specifying your api key in code, ensure this code is not shared publically.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Appending key for api.wandb.ai to your netrc file: /home/diego/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                    Syncing run <strong><a href=\"https://wandb.ai/nlpetroni/assignment-two/runs/3in59x1i\" target=\"_blank\">lucky-universe-416</a></strong> to <a href=\"https://wandb.ai/nlpetroni/assignment-two\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n\n                "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vocabulary is already present. Loading it... Done!\n",
      "The embedding matrix is already present. Loading it... Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING TRAINING\n",
      "Evaluation metrics are computed on validation set\n",
      "\n",
      "EPOCHS | TRAIN LOSS | VALID LOSS | ACCURACY | PRECISION | RECALL |  F1   | V_ACC | V_PREC | V_REC | V_F1\n",
      "[00/50]|      0.559 |      1.353 |    0.597 |     0.560 |  0.943 | 0.702 | 0.595 |  0.556 | 0.940 | 0.699\n",
      "[10/50]|      0.402 |      0.857 |    0.709 |     0.649 |  0.921 | 0.761 | 0.708 |  0.646 | 0.917 | 0.758\n",
      "[20/50]|      0.372 |      0.805 |    0.712 |     0.649 |  0.933 | 0.766 | 0.711 |  0.647 | 0.930 | 0.763\n",
      "[30/50]|      0.351 |      0.832 |    0.730 |     0.671 |  0.911 | 0.773 | 0.730 |  0.670 | 0.906 | 0.770\n",
      "Validation loss increasing for 10 epochs\n",
      "[40/50]|      0.336 |      0.731 |    0.732 |     0.679 |  0.888 | 0.770 | 0.731 |  0.677 | 0.882 | 0.766\n",
      "Early stopping occured at epoch 43 with patience 20\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<br/>Waiting for W&B process to finish, PID 12812... <strong style=\"color:green\">(success).</strong>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d4dacdfd3ded4d13a6c43d00ef36ad86"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\">\n<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>train/accuracy</td><td></td></tr><tr><td>train/f1</td><td></td></tr><tr><td>train/loss</td><td></td></tr><tr><td>train_step</td><td></td></tr><tr><td>valid/accuracy</td><td></td></tr><tr><td>valid/f1</td><td></td></tr><tr><td>valid/loss</td><td></td></tr><tr><td>valid/precision</td><td></td></tr><tr><td>valid/recall</td><td></td></tr><tr><td>valid/vote_accuracy</td><td></td></tr><tr><td>valid/vote_f1</td><td></td></tr><tr><td>valid/vote_precision</td><td></td></tr><tr><td>valid/vote_recall</td><td></td></tr></table><br/></div><div class=\"wandb-col\">\n<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>43</td></tr><tr><td>train/f1</td><td>0.90312</td></tr><tr><td>train_step</td><td>10471</td></tr></table>\n</div></div>\nSynced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)\n<br/>Synced <strong style=\"color:#cdcd00\">lucky-universe-416</strong>: <a href=\"https://wandb.ai/nlpetroni/assignment-two/runs/3in59x1i\" target=\"_blank\">https://wandb.ai/nlpetroni/assignment-two/runs/3in59x1i</a><br/>\nFind logs at: <code>./wandb/run-20211219_010239-3in59x1i/logs</code><br/>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "FactChecker(\n  (emb_layer): Embedding(403484, 100)\n  (encoder): RNNEncoder(\n    (output_layer): LambdaAvg()\n    (rec_module): RNN(100, 64, num_layers=2, batch_first=True, bidirectional=True)\n  )\n  (merger): LambdaConcatenation()\n  (classifier): Sequential(\n    (classifier_fc1): Linear(in_features=256, out_features=128, bias=True)\n    (classifier_ReLU): ReLU()\n    (classifier_fc2): Linear(in_features=128, out_features=1, bias=True)\n  )\n)"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# elman\n",
    "train(optimizer=opt, lr=lr, device=device, n_epochs=epochs, verbose=verbose, tags=[tag, 'elman_avg'],\n",
    "    batch_size=batch_size, encoder='rnn', merger='concatenation', rnn_type='elman',\n",
    "    rnn_output='avg', rec_size=rec_size, hid_size=hid_size, cosine_similarity=cosine_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "9907224891d446b492e468f0e3fd06a1"
     ]
    },
    "id": "iD9H5FwaeDzG",
    "outputId": "853b62fc-a9f2-49b7-8a2a-c1dc4fd14121",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Finishing last run (ID:1e5ezl1r) before initializing another..."
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<br/>Waiting for W&B process to finish, PID 14034... <strong style=\"color:green\">(success).</strong>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "543e047b7a404ee48d1d7b7c0d0b1fc5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\">\n</div><div class=\"wandb-col\">\n</div></div>\nSynced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)\n<br/>Synced <strong style=\"color:#cdcd00\">swift-wind-422</strong>: <a href=\"https://wandb.ai/nlpetroni/assignment-two/runs/1e5ezl1r\" target=\"_blank\">https://wandb.ai/nlpetroni/assignment-two/runs/1e5ezl1r</a><br/>\nFind logs at: <code>./wandb/run-20211219_015800-1e5ezl1r/logs</code><br/>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Successfully finished last run (ID:1e5ezl1r). Initializing new run:<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                    Syncing run <strong><a href=\"https://wandb.ai/nlpetroni/assignment-two/runs/2p22vy98\" target=\"_blank\">decent-galaxy-423</a></strong> to <a href=\"https://wandb.ai/nlpetroni/assignment-two\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n\n                "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vocabulary is already present. Loading it... Done!\n",
      "The embedding matrix is already present. Loading it... Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
      "/home/diego/miniconda3/envs/nlp/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING TRAINING\n",
      "Evaluation metrics are computed on validation set\n",
      "\n",
      "EPOCHS | TRAIN LOSS | VALID LOSS | ACCURACY | PRECISION | RECALL |  F1   | V_ACC | V_PREC | V_REC | V_F1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diego/miniconda3/envs/nlp/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00/50]|      0.582 |      1.411 |    0.520 |     0.512 |  0.990 | 0.675 | 0.516 |  0.508 | 0.990 | 0.672\n",
      "[10/50]|      0.398 |      0.919 |    0.707 |     0.645 |  0.930 | 0.762 | 0.705 |  0.642 | 0.926 | 0.758\n",
      "[20/50]|      0.360 |      0.895 |    0.735 |     0.680 |  0.896 | 0.773 | 0.733 |  0.678 | 0.890 | 0.769\n",
      "Validation loss increasing for 10 epochs\n",
      "[30/50]|      0.336 |      0.861 |    0.733 |     0.675 |  0.909 | 0.775 | 0.732 |  0.673 | 0.904 | 0.771\n",
      "Early stopping occured at epoch 35 with patience 20\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<br/>Waiting for W&B process to finish, PID 14119... <strong style=\"color:green\">(success).</strong>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "13b9e09c7c9e4666b68fd8b76d5322bf"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\">\n<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>train/accuracy</td><td></td></tr><tr><td>train/f1</td><td></td></tr><tr><td>train/loss</td><td></td></tr><tr><td>train_step</td><td></td></tr><tr><td>valid/accuracy</td><td></td></tr><tr><td>valid/f1</td><td></td></tr><tr><td>valid/loss</td><td></td></tr><tr><td>valid/precision</td><td></td></tr><tr><td>valid/recall</td><td></td></tr><tr><td>valid/vote_accuracy</td><td></td></tr><tr><td>valid/vote_f1</td><td></td></tr><tr><td>valid/vote_precision</td><td></td></tr><tr><td>valid/vote_recall</td><td></td></tr></table><br/></div><div class=\"wandb-col\">\n<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>35</td></tr><tr><td>train/f1</td><td>0.90764</td></tr><tr><td>train_step</td><td>8567</td></tr></table>\n</div></div>\nSynced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)\n<br/>Synced <strong style=\"color:#cdcd00\">decent-galaxy-423</strong>: <a href=\"https://wandb.ai/nlpetroni/assignment-two/runs/2p22vy98\" target=\"_blank\">https://wandb.ai/nlpetroni/assignment-two/runs/2p22vy98</a><br/>\nFind logs at: <code>./wandb/run-20211219_020019-2p22vy98/logs</code><br/>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "FactChecker(\n  (emb_layer): Embedding(403484, 100)\n  (encoder): RNNEncoder(\n    (output_layer): LambdaAvg()\n    (rec_module): LSTM(100, 64, num_layers=2, batch_first=True, bidirectional=True)\n  )\n  (merger): LambdaConcatenation()\n  (classifier): Sequential(\n    (classifier_fc1): Linear(in_features=256, out_features=128, bias=True)\n    (classifier_ReLU): ReLU()\n    (classifier_fc2): Linear(in_features=128, out_features=1, bias=True)\n  )\n)"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lstm\n",
    "train(optimizer=opt, lr=lr, device=device, n_epochs=epochs, verbose=verbose, tags=[tag, 'lstm_avg'],\n",
    "    batch_size=batch_size, encoder='rnn', merger='concatenation', rnn_type='lstm',\n",
    "    rnn_output='avg', rec_size=rec_size, hid_size=hid_size, cosine_similarity=cosine_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "a3328937768f4ccabe83eff81a96fe18"
     ]
    },
    "id": "tn5da_pgeDzH",
    "outputId": "1ce2731e-aeda-4d96-b077-08104b3ca6dd",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m If you're specifying your api key in code, ensure this code is not shared publically.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Appending key for api.wandb.ai to your netrc file: /home/diego/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                    Syncing run <strong><a href=\"https://wandb.ai/nlpetroni/assignment-two/runs/1inlv23a\" target=\"_blank\">neat-armadillo-424</a></strong> to <a href=\"https://wandb.ai/nlpetroni/assignment-two\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n\n                "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vocabulary is already present. Loading it... Done!\n",
      "The embedding matrix is already present. Loading it... Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
      "/home/diego/miniconda3/envs/nlp/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING TRAINING\n",
      "Evaluation metrics are computed on validation set\n",
      "\n",
      "EPOCHS | TRAIN LOSS | VALID LOSS | ACCURACY | PRECISION | RECALL |  F1   | V_ACC | V_PREC | V_REC | V_F1\n",
      "[00/50]|      0.562 |      1.454 |    0.610 |     0.568 |  0.948 | 0.710 | 0.610 |  0.566 | 0.948 | 0.708\n",
      "[10/50]|      0.380 |      0.741 |    0.738 |     0.689 |  0.878 | 0.772 | 0.738 |  0.687 | 0.872 | 0.769\n",
      "Validation loss increasing for 10 epochs\n",
      "[20/50]|      0.349 |      0.744 |    0.739 |     0.684 |  0.894 | 0.775 | 0.738 |  0.683 | 0.889 | 0.773\n",
      "[30/50]|      0.328 |      0.860 |    0.747 |     0.689 |  0.907 | 0.783 | 0.745 |  0.687 | 0.901 | 0.779\n",
      "Validation loss increasing for 10 epochs\n",
      "[40/50]|      0.308 |      0.823 |    0.747 |     0.686 |  0.916 | 0.785 | 0.745 |  0.684 | 0.912 | 0.782\n",
      "Early stopping occured at epoch 44 with patience 20\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<br/>Waiting for W&B process to finish, PID 14404... <strong style=\"color:green\">(success).</strong>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c3f6746717fe41189ae5458dfbb8e034"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\">\n<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>train/accuracy</td><td></td></tr><tr><td>train/f1</td><td></td></tr><tr><td>train/loss</td><td></td></tr><tr><td>train_step</td><td></td></tr><tr><td>valid/accuracy</td><td></td></tr><tr><td>valid/f1</td><td></td></tr><tr><td>valid/loss</td><td></td></tr><tr><td>valid/precision</td><td></td></tr><tr><td>valid/recall</td><td></td></tr><tr><td>valid/vote_accuracy</td><td></td></tr><tr><td>valid/vote_f1</td><td></td></tr><tr><td>valid/vote_precision</td><td></td></tr><tr><td>valid/vote_recall</td><td></td></tr></table><br/></div><div class=\"wandb-col\">\n<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>44</td></tr><tr><td>train/f1</td><td>0.92074</td></tr><tr><td>train_step</td><td>10709</td></tr></table>\n</div></div>\nSynced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)\n<br/>Synced <strong style=\"color:#cdcd00\">neat-armadillo-424</strong>: <a href=\"https://wandb.ai/nlpetroni/assignment-two/runs/1inlv23a\" target=\"_blank\">https://wandb.ai/nlpetroni/assignment-two/runs/1inlv23a</a><br/>\nFind logs at: <code>./wandb/run-20211219_023003-1inlv23a/logs</code><br/>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "FactChecker(\n  (emb_layer): Embedding(403484, 100)\n  (encoder): RNNEncoder(\n    (output_layer): LambdaAvg()\n    (rec_module): GRU(100, 64, num_layers=2, batch_first=True, bidirectional=True)\n  )\n  (merger): LambdaConcatenation()\n  (classifier): Sequential(\n    (classifier_fc1): Linear(in_features=256, out_features=128, bias=True)\n    (classifier_ReLU): ReLU()\n    (classifier_fc2): Linear(in_features=128, out_features=1, bias=True)\n  )\n)"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gru\n",
    "train(optimizer=opt, lr=lr, device=device, n_epochs=epochs, verbose=verbose, tags=[tag, 'gru_avg'],\n",
    "    batch_size=batch_size, encoder='rnn', merger='concatenation', rnn_type='gru',\n",
    "    rnn_output='avg', rec_size=rec_size, hid_size=hid_size, cosine_similarity=cosine_similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "RDfhUdY8eDzH"
   },
   "source": [
    "### MLP layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "0f0c7cfaa1b44d3796f08a4ad980b20f"
     ]
    },
    "id": "mR2aA4R-eDzI",
    "outputId": "b65ed54f-998d-47c8-9774-f62ea8952359",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m If you're specifying your api key in code, ensure this code is not shared publically.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Appending key for api.wandb.ai to your netrc file: /home/diego/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                    Syncing run <strong><a href=\"https://wandb.ai/nlpetroni/assignment-two/runs/k82nicd3\" target=\"_blank\">brisk-spaceship-425</a></strong> to <a href=\"https://wandb.ai/nlpetroni/assignment-two\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n\n                "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vocabulary is already present. Loading it... Done!\n",
      "The embedding matrix is already present. Loading it... Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING TRAINING\n",
      "Evaluation metrics are computed on validation set\n",
      "\n",
      "EPOCHS | TRAIN LOSS | VALID LOSS | ACCURACY | PRECISION | RECALL |  F1   | V_ACC | V_PREC | V_REC | V_F1\n",
      "[00/50]|      0.501 |      0.627 |    0.651 |     0.610 |  0.847 | 0.709 | 0.652 |  0.610 | 0.841 | 0.707\n",
      "[10/50]|      0.233 |      1.063 |    0.659 |     0.606 |  0.922 | 0.731 | 0.659 |  0.604 | 0.918 | 0.729\n",
      "Validation loss increasing for 10 epochs\n",
      "[20/50]|      0.137 |      1.434 |    0.671 |     0.620 |  0.889 | 0.731 | 0.671 |  0.619 | 0.885 | 0.728\n",
      "Early stopping occured at epoch 23 with patience 20\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<br/>Waiting for W&B process to finish, PID 14554... <strong style=\"color:green\">(success).</strong>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ba1cdbaadadf40369d5bf9287968d33c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\">\n<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>train/accuracy</td><td></td></tr><tr><td>train/f1</td><td></td></tr><tr><td>train/loss</td><td></td></tr><tr><td>train_step</td><td></td></tr><tr><td>valid/accuracy</td><td></td></tr><tr><td>valid/f1</td><td></td></tr><tr><td>valid/loss</td><td></td></tr><tr><td>valid/precision</td><td></td></tr><tr><td>valid/recall</td><td></td></tr><tr><td>valid/vote_accuracy</td><td></td></tr><tr><td>valid/vote_f1</td><td></td></tr><tr><td>valid/vote_precision</td><td></td></tr><tr><td>valid/vote_recall</td><td></td></tr></table><br/></div><div class=\"wandb-col\">\n<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>23</td></tr><tr><td>train/f1</td><td>1.0</td></tr><tr><td>train_step</td><td>5591</td></tr></table>\n</div></div>\nSynced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)\n<br/>Synced <strong style=\"color:#cdcd00\">brisk-spaceship-425</strong>: <a href=\"https://wandb.ai/nlpetroni/assignment-two/runs/k82nicd3\" target=\"_blank\">https://wandb.ai/nlpetroni/assignment-two/runs/k82nicd3</a><br/>\nFind logs at: <code>./wandb/run-20211219_030723-k82nicd3/logs</code><br/>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "FactChecker(\n  (emb_layer): Embedding(403484, 100)\n  (encoder): MLPEncoder(\n    (evidence_mlp): Sequential(\n      (mlp_fc1): Linear(in_features=6600, out_features=100, bias=True)\n      (mlp_ReLU): ReLU()\n      (mlp_fc2): Linear(in_features=100, out_features=100, bias=True)\n    )\n    (claim_mlp): Sequential(\n      (mlp_fc1): Linear(in_features=1800, out_features=100, bias=True)\n      (mlp_ReLU): ReLU()\n      (mlp_fc2): Linear(in_features=100, out_features=100, bias=True)\n    )\n  )\n  (merger): LambdaConcatenation()\n  (classifier): Sequential(\n    (classifier_fc1): Linear(in_features=200, out_features=100, bias=True)\n    (classifier_ReLU): ReLU()\n    (classifier_fc2): Linear(in_features=100, out_features=1, bias=True)\n  )\n)"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(optimizer=opt, lr=lr, device=device, n_epochs=epochs, verbose=verbose,  tags=[tag, 'mlp'],\n",
    "    batch_size=batch_size, encoder='mlp', merger='concatenation', cosine_similarity=cosine_similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "TLpzTPkReDzJ"
   },
   "source": [
    "### Bag of vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "ad9017776856468584242d474d5784e4"
     ]
    },
    "id": "bqX_UdQoeDzK",
    "outputId": "ba0f153b-df4c-42a9-a67c-862e17c10e8a",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m If you're specifying your api key in code, ensure this code is not shared publically.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Appending key for api.wandb.ai to your netrc file: /home/diego/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                    Syncing run <strong><a href=\"https://wandb.ai/nlpetroni/assignment-two/runs/10je5nfi\" target=\"_blank\">breezy-breeze-426</a></strong> to <a href=\"https://wandb.ai/nlpetroni/assignment-two\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n\n                "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vocabulary is already present. Loading it... Done!\n",
      "The embedding matrix is already present. Loading it... Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING TRAINING\n",
      "Evaluation metrics are computed on validation set\n",
      "\n",
      "EPOCHS | TRAIN LOSS | VALID LOSS | ACCURACY | PRECISION | RECALL |  F1   | V_ACC | V_PREC | V_REC | V_F1\n",
      "[00/50]|      0.587 |      1.393 |    0.504 |     0.504 |  1.000 | 0.670 | 0.500 |  0.500 | 1.000 | 0.666\n",
      "[10/50]|      0.527 |      0.843 |    0.609 |     0.581 |  0.806 | 0.675 | 0.609 |  0.579 | 0.796 | 0.671\n",
      "Validation loss increasing for 10 epochs\n",
      "[20/50]|      0.514 |      0.832 |    0.615 |     0.587 |  0.793 | 0.675 | 0.614 |  0.585 | 0.781 | 0.669\n",
      "Early stopping occured at epoch 25 with patience 20\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<br/>Waiting for W&B process to finish, PID 14617... <strong style=\"color:green\">(success).</strong>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "137569233c114aeb9ffe448f5f968e79"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\">\n<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>train/accuracy</td><td></td></tr><tr><td>train/f1</td><td></td></tr><tr><td>train/loss</td><td></td></tr><tr><td>train_step</td><td></td></tr><tr><td>valid/accuracy</td><td></td></tr><tr><td>valid/f1</td><td></td></tr><tr><td>valid/loss</td><td></td></tr><tr><td>valid/precision</td><td></td></tr><tr><td>valid/recall</td><td></td></tr><tr><td>valid/vote_accuracy</td><td></td></tr><tr><td>valid/vote_f1</td><td></td></tr><tr><td>valid/vote_precision</td><td></td></tr><tr><td>valid/vote_recall</td><td></td></tr></table><br/></div><div class=\"wandb-col\">\n<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>25</td></tr><tr><td>train/f1</td><td>0.86303</td></tr><tr><td>train_step</td><td>6187</td></tr></table>\n</div></div>\nSynced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)\n<br/>Synced <strong style=\"color:#cdcd00\">breezy-breeze-426</strong>: <a href=\"https://wandb.ai/nlpetroni/assignment-two/runs/10je5nfi\" target=\"_blank\">https://wandb.ai/nlpetroni/assignment-two/runs/10je5nfi</a><br/>\nFind logs at: <code>./wandb/run-20211219_031032-10je5nfi/logs</code><br/>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "FactChecker(\n  (emb_layer): Embedding(403484, 100)\n  (encoder): BagOfVectorsEncoder()\n  (merger): LambdaConcatenation()\n  (classifier): Sequential(\n    (classifier_fc1): Linear(in_features=200, out_features=100, bias=True)\n    (classifier_ReLU): ReLU()\n    (classifier_fc2): Linear(in_features=100, out_features=1, bias=True)\n  )\n)"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(optimizer=opt, lr=lr, device=device, n_epochs=epochs, verbose=verbose,  tags=[tag, 'bow'],\n",
    "      batch_size=batch_size, encoder='bag', merger='concatenation', cosine_similarity=cosine_similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "M4hGLXSGeDzK",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The best sentence embedding is taking **the last state of an RNN encoder (LSTM)**. Indeed it reaches the highest values across all the runs in F1 score (both standard and group voting) and in accuracy (only group voting, since taking the average of the states of a GRU RNN results in a barely better standard accuracy)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "PLaiormeLfBU"
   },
   "source": [
    "## Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "NhOy1VtALfBV",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tag = 'merging choice'\n",
    "encoder = 'rnn'\n",
    "rnn_type = 'gru'\n",
    "rnn_output = 'avg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "HlXQt3ewLfBV"
   },
   "source": [
    "### Concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "9Ux24NZyLfBV",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mdiegochine\u001B[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m If you're specifying your api key in code, ensure this code is not shared publically.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Appending key for api.wandb.ai to your netrc file: /home/diego/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                    Syncing run <strong><a href=\"https://wandb.ai/nlpetroni/assignment-two/runs/3iv5txnv\" target=\"_blank\">pretty-salad-428</a></strong> to <a href=\"https://wandb.ai/nlpetroni/assignment-two\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n\n                "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vocabulary is already present. Loading it... Done!\n",
      "The embedding matrix is already present. Loading it... Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING TRAINING\n",
      "Evaluation metrics are computed on validation set\n",
      "\n",
      "EPOCHS | TRAIN LOSS | VALID LOSS | ACCURACY | PRECISION | RECALL |  F1   | V_ACC | V_PREC | V_REC | V_F1\n",
      "[00/50]|      0.575 |      1.200 |    0.518 |     0.511 |  0.991 | 0.675 | 0.515 |  0.507 | 0.990 | 0.671\n",
      "[10/50]|      0.397 |      0.745 |    0.731 |     0.682 |  0.875 | 0.767 | 0.730 |  0.680 | 0.868 | 0.762\n",
      "[20/50]|      0.366 |      0.766 |    0.743 |     0.690 |  0.891 | 0.778 | 0.742 |  0.688 | 0.884 | 0.774\n",
      "[30/50]|      0.346 |      0.670 |    0.752 |     0.706 |  0.870 | 0.780 | 0.750 |  0.704 | 0.862 | 0.775\n",
      "Validation loss increasing for 10 epochs\n",
      "[40/50]|      0.331 |      0.754 |    0.746 |     0.690 |  0.901 | 0.782 | 0.743 |  0.687 | 0.894 | 0.777\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<br/>Waiting for W&B process to finish, PID 18972... <strong style=\"color:green\">(success).</strong>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "751fa00b71f741e284fa66d03cc6f2e8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\">\n<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>train/accuracy</td><td></td></tr><tr><td>train/f1</td><td></td></tr><tr><td>train/loss</td><td></td></tr><tr><td>train_step</td><td></td></tr><tr><td>valid/accuracy</td><td></td></tr><tr><td>valid/f1</td><td></td></tr><tr><td>valid/loss</td><td></td></tr><tr><td>valid/precision</td><td></td></tr><tr><td>valid/recall</td><td></td></tr><tr><td>valid/vote_accuracy</td><td></td></tr><tr><td>valid/vote_f1</td><td></td></tr><tr><td>valid/vote_precision</td><td></td></tr><tr><td>valid/vote_recall</td><td></td></tr></table><br/></div><div class=\"wandb-col\">\n<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>train/f1</td><td>0.90722</td></tr><tr><td>train_step</td><td>11899</td></tr></table>\n</div></div>\nSynced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)\n<br/>Synced <strong style=\"color:#cdcd00\">pretty-salad-428</strong>: <a href=\"https://wandb.ai/nlpetroni/assignment-two/runs/3iv5txnv\" target=\"_blank\">https://wandb.ai/nlpetroni/assignment-two/runs/3iv5txnv</a><br/>\nFind logs at: <code>./wandb/run-20211219_093238-3iv5txnv/logs</code><br/>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "FactChecker(\n  (emb_layer): Embedding(403484, 100)\n  (encoder): RNNEncoder(\n    (output_layer): LambdaAvg()\n    (rec_module): GRU(100, 50, batch_first=True, bidirectional=True)\n  )\n  (merger): LambdaConcatenation()\n  (classifier): Sequential(\n    (classifier_fc1): Linear(in_features=200, out_features=100, bias=True)\n    (classifier_ReLU): ReLU()\n    (classifier_fc2): Linear(in_features=100, out_features=1, bias=True)\n  )\n)"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(optimizer=opt, lr=lr, device=device, n_epochs=epochs, verbose=verbose,  tags=[tag, 'concatenation'],\n",
    "    batch_size=batch_size, encoder=encoder, rnn_type=rnn_type, rnn_output=rnn_output, \n",
    "    merger='concatenation', cosine_similarity=cosine_similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "hr1CZt0yLfBV"
   },
   "source": [
    "### Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "50iwnFzcLfBV",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m If you're specifying your api key in code, ensure this code is not shared publically.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Appending key for api.wandb.ai to your netrc file: /home/diego/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                    Syncing run <strong><a href=\"https://wandb.ai/nlpetroni/assignment-two/runs/11pbxu4y\" target=\"_blank\">zany-water-429</a></strong> to <a href=\"https://wandb.ai/nlpetroni/assignment-two\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n\n                "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vocabulary is already present. Loading it... Done!\n",
      "The embedding matrix is already present. Loading it... Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING TRAINING\n",
      "Evaluation metrics are computed on validation set\n",
      "\n",
      "EPOCHS | TRAIN LOSS | VALID LOSS | ACCURACY | PRECISION | RECALL |  F1   | V_ACC | V_PREC | V_REC | V_F1\n",
      "[00/50]|      0.590 |      1.722 |    0.504 |     0.504 |  1.000 | 0.670 | 0.500 |  0.500 | 1.000 | 0.666\n",
      "[10/50]|      0.426 |      0.918 |    0.707 |     0.659 |  0.869 | 0.749 | 0.705 |  0.655 | 0.863 | 0.745\n",
      "[20/50]|      0.391 |      0.972 |    0.730 |     0.679 |  0.879 | 0.766 | 0.727 |  0.675 | 0.873 | 0.762\n",
      "Validation loss increasing for 10 epochs\n",
      "[30/50]|      0.370 |      0.941 |    0.738 |     0.690 |  0.872 | 0.771 | 0.735 |  0.686 | 0.864 | 0.765\n",
      "Early stopping occured at epoch 35 with patience 20\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<br/>Waiting for W&B process to finish, PID 19116... <strong style=\"color:green\">(success).</strong>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d05b3c11cb424e34ab612a40e2a78735"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\">\n<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>train/accuracy</td><td></td></tr><tr><td>train/f1</td><td></td></tr><tr><td>train/loss</td><td></td></tr><tr><td>train_step</td><td></td></tr><tr><td>valid/accuracy</td><td></td></tr><tr><td>valid/f1</td><td></td></tr><tr><td>valid/loss</td><td></td></tr><tr><td>valid/precision</td><td></td></tr><tr><td>valid/recall</td><td></td></tr><tr><td>valid/vote_accuracy</td><td></td></tr><tr><td>valid/vote_f1</td><td></td></tr><tr><td>valid/vote_precision</td><td></td></tr><tr><td>valid/vote_recall</td><td></td></tr></table><br/></div><div class=\"wandb-col\">\n<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>35</td></tr><tr><td>train/f1</td><td>0.90016</td></tr><tr><td>train_step</td><td>8567</td></tr></table>\n</div></div>\nSynced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)\n<br/>Synced <strong style=\"color:#cdcd00\">zany-water-429</strong>: <a href=\"https://wandb.ai/nlpetroni/assignment-two/runs/11pbxu4y\" target=\"_blank\">https://wandb.ai/nlpetroni/assignment-two/runs/11pbxu4y</a><br/>\nFind logs at: <code>./wandb/run-20211219_100240-11pbxu4y/logs</code><br/>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "FactChecker(\n  (emb_layer): Embedding(403484, 100)\n  (encoder): RNNEncoder(\n    (output_layer): LambdaAvg()\n    (rec_module): GRU(100, 50, batch_first=True, bidirectional=True)\n  )\n  (merger): LambdaSum()\n  (classifier): Sequential(\n    (classifier_fc1): Linear(in_features=100, out_features=50, bias=True)\n    (classifier_ReLU): ReLU()\n    (classifier_fc2): Linear(in_features=50, out_features=1, bias=True)\n  )\n)"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(optimizer=opt, lr=lr, device=device, n_epochs=epochs, verbose=verbose,  tags=[tag, 'sum'],\n",
    "    batch_size=batch_size, encoder=encoder, rnn_type=rnn_type, rnn_output=rnn_output, \n",
    "    merger='sum', cosine_similarity=cosine_similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "uP65_KYbLfBW"
   },
   "source": [
    "### Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "Idw3edQDLfBW",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m If you're specifying your api key in code, ensure this code is not shared publically.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Appending key for api.wandb.ai to your netrc file: /home/diego/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                    Syncing run <strong><a href=\"https://wandb.ai/nlpetroni/assignment-two/runs/2ycgp089\" target=\"_blank\">sandy-dust-430</a></strong> to <a href=\"https://wandb.ai/nlpetroni/assignment-two\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n\n                "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vocabulary is already present. Loading it... Done!\n",
      "The embedding matrix is already present. Loading it... Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
      "/home/diego/miniconda3/envs/nlp/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING TRAINING\n",
      "Evaluation metrics are computed on validation set\n",
      "\n",
      "EPOCHS | TRAIN LOSS | VALID LOSS | ACCURACY | PRECISION | RECALL |  F1   | V_ACC | V_PREC | V_REC | V_F1\n",
      "[00/50]|      0.595 |      1.696 |    0.504 |     0.504 |  1.000 | 0.670 | 0.500 |  0.500 | 1.000 | 0.666\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_18619/285175270.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m train(optimizer=opt, lr=lr, device=device, n_epochs=epochs, verbose=verbose,  tags=[tag, 'mean'],\n\u001B[0m\u001B[1;32m      2\u001B[0m     \u001B[0mbatch_size\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mbatch_size\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mencoder\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mencoder\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrnn_type\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mrnn_type\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrnn_output\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mrnn_output\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m     merger='mean', cosine_similarity=cosine_similarity)\n",
      "\u001B[0;32m/tmp/ipykernel_18619/2328452657.py\u001B[0m in \u001B[0;36mtrain\u001B[0;34m(optimizer, lr, device, n_epochs, verbose, batch_size, test, tags, seed, **model_params)\u001B[0m\n\u001B[1;32m     86\u001B[0m   \u001B[0mearly_stopped\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mFalse\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     87\u001B[0m   \u001B[0;32mwhile\u001B[0m \u001B[0mepoch\u001B[0m \u001B[0;34m<\u001B[0m \u001B[0mn_epochs\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mearly_stopped\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 88\u001B[0;31m     \u001B[0mlog_dict\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtraining_step\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moptimizer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mloss\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrain_dl\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     89\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mtest\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     90\u001B[0m       \u001B[0mlog_dict\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mevaluate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalid_loss\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalid_dl\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/tmp/ipykernel_18619/3483978460.py\u001B[0m in \u001B[0;36mtraining_step\u001B[0;34m(model, optimizer, loss_fn, data_loader, device)\u001B[0m\n\u001B[1;32m      8\u001B[0m     \u001B[0mlabels\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlabels\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 10\u001B[0;31m     \u001B[0moutputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mclaims\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcl_lengths\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mevidences\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mev_lengths\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     11\u001B[0m     \u001B[0moutputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0moutputs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mview\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0moutputs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msize\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     12\u001B[0m     \u001B[0mloss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mloss_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0moutputs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlabels\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/nlp/lib/python3.9/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1100\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1101\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1102\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1103\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1104\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/tmp/ipykernel_18619/2846165940.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, claim, claim_lengths, evidence, evidence_lengths, debug)\u001B[0m\n\u001B[1;32m     64\u001B[0m     \u001B[0;31m# Sentence embedding\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     65\u001B[0m     \u001B[0mclaim\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mencoder\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mclaim\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mclaim_lengths\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 66\u001B[0;31m     \u001B[0mevidence\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mencoder\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mevidence\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mevidence_lengths\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     67\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mdebug\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     68\u001B[0m       \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"After phrase encoding\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/nlp/lib/python3.9/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1118\u001B[0m             \u001B[0minput\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mbw_hook\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msetup_input_hook\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1119\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1120\u001B[0;31m         \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1121\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0m_global_forward_hooks\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_forward_hooks\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1122\u001B[0m             \u001B[0;32mfor\u001B[0m \u001B[0mhook\u001B[0m \u001B[0;32min\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0m_global_forward_hooks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_forward_hooks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/tmp/ipykernel_18619/2416488105.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, x, lengths)\u001B[0m\n\u001B[1;32m     47\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mh_n\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtuple\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     48\u001B[0m             \u001B[0mh_n\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mh_n\u001B[0m  \u001B[0;31m# drop cell state\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 49\u001B[0;31m         \u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mutils\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrnn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpad_packed_sequence\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbatch_first\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     50\u001B[0m         \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0moutput_layer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mh_n\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     51\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/nlp/lib/python3.9/site-packages/torch/nn/utils/rnn.py\u001B[0m in \u001B[0;36mpad_packed_sequence\u001B[0;34m(sequence, batch_first, padding_value, total_length)\u001B[0m\n\u001B[1;32m    317\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0munsorted_indices\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    318\u001B[0m         \u001B[0mbatch_dim\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m0\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mbatch_first\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 319\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mpadded_output\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mindex_select\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbatch_dim\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0munsorted_indices\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlengths\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0munsorted_indices\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    320\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mpadded_output\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlengths\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    321\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "train(optimizer=opt, lr=lr, device=device, n_epochs=epochs, verbose=verbose,  tags=[tag, 'mean'],\n",
    "    batch_size=batch_size, encoder=encoder, rnn_type=rnn_type, rnn_output=rnn_output, \n",
    "    merger='mean', cosine_similarity=cosine_similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "nkxKjbysLfBW"
   },
   "source": [
    "The best merging strategy is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "zgTU1HnkLfBW"
   },
   "source": [
    "## Other hyperparameters tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O3fG3iucLfBX",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tag = 'hyperparameters tuning'\n",
    "merger = 'mean'\n",
    "\n",
    "for opt in ('rmsprop', 'adam'):\n",
    "    for cosine_similarity in (True, False):\n",
    "        for run in range(50):\n",
    "            lr = random.uniform(1e-5, 5e-4)\n",
    "            rec_size = random.randint(1, 3)\n",
    "            hid_size = random.randint(32, 128)\n",
    "            n_layers_classifier = random.randint(1, 3)\n",
    "            train(optimizer=opt, lr=lr, device=device, n_epochs=epochs, verbose=verbose,  tags=[tag, 'tuning'],\n",
    "                batch_size=batch_size, encoder=encoder, rnn_type=rnn_type, rnn_output=rnn_output, \n",
    "                merger=merger, cosine_similarity=cosine_similarity, rec_size=rec_size, hid_size=hid_size, \n",
    "                n_layers_classifier=n_layers_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "solution_2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "13f9843ea1ba4edfae22ae60a3352dd2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2d099f25910b475ebbc608e027842fdc",
      "placeholder": "",
      "style": "IPY_MODEL_f2f2500670d84a1a865b5e16565158d1",
      "value": " 0.05MB of 0.05MB uploaded (0.00MB deduped)\r"
     }
    },
    "18055ba906c2451087095587408664fb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "24db48b596bb44df80a2997979c7ddff": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2584485976c74f71a67c7c3c5e6ce8f6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2d099f25910b475ebbc608e027842fdc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "31bb4140f41342bca4123f339ea47951": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "44795c98c2b94a58ab4bfd061346121d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_699d4e831111401781e63047043669c8",
      "placeholder": "",
      "style": "IPY_MODEL_31bb4140f41342bca4123f339ea47951",
      "value": " 0.01MB of 0.01MB uploaded (0.00MB deduped)\r"
     }
    },
    "6224d7fc953845fb9be0f4a58cf69ead": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_44795c98c2b94a58ab4bfd061346121d",
       "IPY_MODEL_a4ec98a7c2e34609affebfff4a884cee"
      ],
      "layout": "IPY_MODEL_a8ad1b37e1114bc79a6addd0e2460bd5"
     }
    },
    "699d4e831111401781e63047043669c8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "89ae60240f2842948f570842aeaf5539": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_13f9843ea1ba4edfae22ae60a3352dd2",
       "IPY_MODEL_999d30f84fd4472abda076597e4c6c39"
      ],
      "layout": "IPY_MODEL_24db48b596bb44df80a2997979c7ddff"
     }
    },
    "999d30f84fd4472abda076597e4c6c39": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f19c8557e81245979dc373384b2a37f7",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2584485976c74f71a67c7c3c5e6ce8f6",
      "value": 1
     }
    },
    "a4ec98a7c2e34609affebfff4a884cee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_eb84a15b7315468893060362025a9491",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_18055ba906c2451087095587408664fb",
      "value": 1
     }
    },
    "a8ad1b37e1114bc79a6addd0e2460bd5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eb84a15b7315468893060362025a9491": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f19c8557e81245979dc373384b2a37f7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f2f2500670d84a1a865b5e16565158d1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}