{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "solution_2.ipynb",
   "provenance": [],
   "authorship_tag": "ABX9TyMMdN1gTucqm71FuUscYe0C",
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/NLPetroni/assignment_two/blob/main/solution_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m5ldIOU6KPl4"
   },
   "source": [
    "# Imports and downloads\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zpI5pddAJRU5",
    "outputId": "ecd6986b-6041-4fd2-d829-3cd214bc709d"
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "\n",
    "try:\n",
    "  import google.colab\n",
    "  IN_COLAB = True\n",
    "except:\n",
    "  IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "  %cd /content\n",
    "  !rm -rf assignment_two &> /dev/null\n",
    "  !git clone https://github.com/NLPetroni/assignment_two &> /dev/null\n",
    "  %cd assignment_two\n",
    "  sys.path.append(os.getcwd())\n",
    "  !git clone https://gitlab.com/sasso-effe/nlp-assignment-data.git &> /dev/null\n",
    "  !mv nlp-assignment-data/embedding_matrix.npy res/embedding_matrix.npy\n",
    "  !rm -rf nlp-assignment-data\n"
   ],
   "execution_count": 26,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "o2uzDyzCKrGy"
   },
   "source": [
    "from src import utils\n",
    "import re\n",
    "from functools import reduce\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from typing import List, Callable, Dict\n",
    "import random\n",
    "import torch\n",
    "from torch import nn"
   ],
   "execution_count": 27,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "0zr8CGx9JmRN",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "dd324c51-8495-4b3c-cae3-e203108be5f2"
   },
   "source": [
    "utils.download_data('dataset')\n",
    "train_set = pd.read_csv(\"dataset/train_pairs.csv\")\n",
    "val_set = pd.read_csv(\"dataset/val_pairs.csv\")\n",
    "test_set = pd.read_csv(\"dataset/test_pairs.csv\")"
   ],
   "execution_count": 28,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eZ59KJhcJr5I",
    "outputId": "ced42a19-7dcb-4bfa-fe03-2400f68aa6ce"
   },
   "source": [
    "print(train_set.columns)\n",
    "print(\"Total rows of the train set: {:d}\".format(len(train_set)))\n",
    "print(\"Total rows of the validation set: {:d}\".format(len(val_set)))\n",
    "print(\"Total rows of the test set: {:d}\".format(len(test_set)))"
   ],
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'Claim', 'Evidence', 'ID', 'Label'], dtype='object')\n",
      "Total rows of the train set: 121740\n",
      "Total rows of the validation set: 7165\n",
      "Total rows of the test set: 7189\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kTfRZo0zJv16",
    "outputId": "0fa2f775-83b0-4b39-bd19-733d8e334bdb"
   },
   "source": [
    "train_set['Label'].value_counts()"
   ],
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "SUPPORTS    89389\nREFUTES     32351\nName: Label, dtype: int64"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ib-Br_fNRhVa",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "f7ca260d-673e-46b7-ba33-c11dcc0a3b8e"
   },
   "source": [
    "print(train_set.iloc[0]['Evidence'])"
   ],
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\tHemsworth has also appeared in the science fiction action film Star Trek -LRB- 2009 -RRB- , the thriller adventure A Perfect Getaway -LRB- 2009 -RRB- , the horror comedy The Cabin in the Woods -LRB- 2012 -RRB- , the dark-fantasy action film Snow White and the Huntsman -LRB- 2012 -RRB- , the war film Red Dawn -LRB- 2012 -RRB- , and the biographical sports drama film Rush -LRB- 2013 -RRB- .\tStar Trek\tStar Trek (film)\tA Perfect Getaway\tA Perfect Getaway\tThe Cabin in the Woods\tThe Cabin in the Woods\tSnow White and the Huntsman\tSnow White and the Huntsman\tRed Dawn\tRed Dawn (2012 film)\tRush\tRush (2013 film)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yBtVzSl_J0CR"
   },
   "source": [
    "# Dataset pre-processing and conversion"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "mps78KxwJ1e6",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "39d32ef1-6000-4326-d7ce-680a90f9a02b"
   },
   "source": [
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;\\t-]')\n",
    "GOOD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "BAD_SYMBOLS_RE = re.compile('(-LRB-)|(-RRB-)|(-LSB-)|(-RSB-)')\n",
    "INSIDE_SQAURE_BRACKETS_RE = re.compile('(-LSB-).*?(-RSB-)')\n",
    "\n",
    "try:\n",
    "    STOPWORDS = set(stopwords.words('english'))\n",
    "except LookupError:\n",
    "    nltk.download('stopwords')\n",
    "    STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def remove_inside_square_brackets(text: str) -> str:\n",
    "    return INSIDE_SQAURE_BRACKETS_RE.sub('', text)\n",
    "\n",
    "def remove_bad_symbols(text: str) -> str:\n",
    "    return BAD_SYMBOLS_RE.sub('', text)\n",
    "\n",
    "def remove_final_tags(text: str) -> str:\n",
    "   return re.sub('\\.\\t.*?$', '', text) \n",
    "\n",
    "def lower(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Transforms given text to lower case.\n",
    "    Example:\n",
    "    Input: 'I really like New York city'\n",
    "    Output: 'i really like new your city'\n",
    "    \"\"\"\n",
    "\n",
    "    return text.lower()\n",
    "\n",
    "def replace_special_characters(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Replaces special characters, such as paranthesis,\n",
    "    with spacing character\n",
    "    \"\"\"\n",
    "\n",
    "    return REPLACE_BY_SPACE_RE.sub(' ', text)\n",
    "\n",
    "def replace_br(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Replaces br characters\n",
    "    \"\"\"\n",
    "\n",
    "    return text.replace('</br>', '')\n",
    "\n",
    "def filter_out_uncommon_symbols(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Removes any special character that is not in the\n",
    "    good symbols list (check regular expression)\n",
    "    \"\"\"\n",
    "\n",
    "    return GOOD_SYMBOLS_RE.sub('', text)\n",
    "\n",
    "def remove_stopwords(text: str) -> str:\n",
    "    return ' '.join([x for x in text.split() if x and x not in STOPWORDS])\n",
    "\n",
    "\n",
    "def strip_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Removes any left or right spacing (including carriage return) from text.\n",
    "    Example:\n",
    "    Input: '  This assignment is cool\\n'\n",
    "    Output: 'This assignment is cool'\n",
    "    \"\"\"\n",
    "\n",
    "    return text.strip()\n",
    "\n",
    "def split_text(text: str) -> List:\n",
    "  return text.split()\n",
    "\n",
    "PREPROCESSING_PIPELINE = [\n",
    "                          remove_inside_square_brackets,\n",
    "                          remove_bad_symbols,\n",
    "                          lower,\n",
    "                          remove_final_tags,\n",
    "                          replace_special_characters,\n",
    "                          filter_out_uncommon_symbols,\n",
    "                          remove_stopwords,\n",
    "                          strip_text,\n",
    "                          split_text\n",
    "                          ]\n",
    "\n",
    "# Anchor method\n",
    "\n",
    "def text_prepare(text: str,\n",
    "                 filter_methods: List[Callable[[str], str]] = None) -> str:\n",
    "    \"\"\"\n",
    "    Applies a list of pre-processing functions in sequence (reduce).\n",
    "    Note that the order is important here!\n",
    "    \"\"\"\n",
    "\n",
    "    filter_methods = filter_methods if filter_methods is not None else PREPROCESSING_PIPELINE\n",
    "\n",
    "    return reduce(lambda txt, f: f(txt), filter_methods, text)\n",
    "\n",
    "\n",
    "# In the evidences there is an id at the beginning of the sequence which is\n",
    "# removed with the splice [:1]\n",
    "train_set['Evidence'] = train_set['Evidence'].apply(lambda txt: text_prepare(txt)[1:])\n",
    "train_set['Claim'] = train_set['Claim'].apply(lambda txt: text_prepare(txt))\n",
    "\n",
    "val_set['Evidence'] = val_set['Evidence'].apply(lambda txt: text_prepare(txt)[1:])\n",
    "val_set['Claim'] = val_set['Claim'].apply(lambda txt: text_prepare(txt))\n",
    "\n",
    "test_set['Evidence'] = test_set['Evidence'].apply(lambda txt: text_prepare(txt)[1:])\n",
    "test_set['Claim'] = test_set['Claim'].apply(lambda txt: text_prepare(txt))"
   ],
   "execution_count": 32,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "2XUEfrJOhEQZ"
   },
   "source": [
    "voc_evidence = [item for sublist in train_set[:]['Evidence'] for item in sublist]\n",
    "voc_claim = [item for sublist in train_set[:]['Claim'] for item in sublist]\n",
    "vocabulary = list(set(voc_evidence + voc_claim))\n",
    "\n",
    "def tokenize(input: List) -> torch.Tensor:\n",
    "  result = list(map(lambda x: vocabulary.index(x), input))\n",
    "  return torch.tensor(result)\n",
    "\n",
    "def detokenize(input: torch.Tensor) -> List:\n",
    "  result = input.tolist()\n",
    "  result = list(map(lambda x: vocabulary[x], result))\n",
    "  return result"
   ],
   "execution_count": 33,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    \"\"\"Simple dataset class to use dataloaders (batching) \"\"\"\n",
    "    def __init__(self, claims, evidences, labels):\n",
    "        self.inputs = inputs\n",
    "        self.labels = labels\n",
    "    def __getitem__(self, idx):\n",
    "        return self.claims[idx], self.evidences[idx], labels[idx]\n",
    "    def __len__(self):\n",
    "        return self.inputs.shape[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 34,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fo02GPAtUBlt"
   },
   "source": [
    "## Glove"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "gbq8J24TXLdm",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "b934a906-880a-4b85-f5a9-e1aca01e3391"
   },
   "source": [
    "import pickle\n",
    "\n",
    "if (os.path.exists(\"res/vocabulary.pkl\") and os.path.exists(\"res/embedding_matrix.npy\")):\n",
    "  print('The vocabulary and the embedding matrix are already present. Loading them...')\n",
    "  with open('res/vocabulary.pkl', 'rb') as f:\n",
    "    VOCABULARY = pickle.load(f)\n",
    "  EMBEDDING_MATRIX = np.load(\"res/embedding_matrix.npy\", )\n",
    "  print(\"Done!\")\n",
    "  \n",
    "else:\n",
    "  print(\"The vocabulary and the embedding matrix are NOT present. Creating them...\")\n",
    "  TRAIN_VOC = set(vocabulary)\n",
    "  voc_evidence = [item for sublist in val_set[:]['Evidence'] for item in sublist]\n",
    "  voc_claim = [item for sublist in val_set[:]['Claim'] for item in sublist]\n",
    "  VAL_VOC = set(voc_evidence + voc_claim)\n",
    "\n",
    "  inputs = train_set[:]['Evidence'].tolist() + train_set[:]['Claim'].tolist()\n",
    "  glove_voc, embedding_matrix = utils.get_glove(number_token=False)\n",
    "  vocabulary, embedding_matrix = utils.add_oov(glove_voc, TRAIN_VOC, embedding_matrix, inputs)\n",
    "  inputs = val_set[:]['Evidence'].tolist() + val_set[:]['Claim'].tolist()\n",
    "  vocabulary, embedding_matrix = utils.add_oov(vocabulary, VAL_VOC, embedding_matrix, inputs)\n",
    "\n",
    "  with open(\"vocabulary.pkl\", \"wb\") as file:\n",
    "    pickle.dump(vocabulary, file)\n",
    "  np.save(\"embedding_matrix.npy\", embedding_matrix)\n",
    "  print(\"Vocabulary and embedding matrix created! Remember to download the generated files.\")"
   ],
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vocabulary and the embedding matrix are already present. Loading them...\n",
      "Done!\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Vcu8TTVqRLp"
   },
   "source": [
    "# Model definition"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "J0Hk8G5NcuS4"
   },
   "source": [
    "def get_classifier(name:str,\n",
    "                    w_in: int,\n",
    "                    w_hidden: int,\n",
    "                    w_out: int) -> nn.Sequential:\n",
    "    \"\"\"Gets a sequential container with a linear+relu+linear classifier\n",
    "\n",
    "    Args:\n",
    "        name: the name prefix to append to each layer in the container.\n",
    "        w_in: the number of the input features.\n",
    "        w_hidden: the number of internal weights\n",
    "        w_out: the number of the output features.\n",
    "\n",
    "    Returns: the created sequential.\n",
    "    \"\"\"\n",
    "    container = nn.Sequential()\n",
    "    container.add_module(f'{name}_fc1', nn.Linear(in_features=w_in, out_features=w_hidden))    \n",
    "    container.add_module(f'{name}_ReLU', nn.ReLU(inplace=True))\n",
    "    container.add_module(f'{name}_fc2', nn.Linear(in_features=w_hidden, out_features=w_out))    \n",
    "    return container\n",
    "\n",
    " \n",
    "class RNNEncoder(torch.nn.Module):\n",
    "\n",
    "  def __init__(self, input_size, hidden_size, num_layers, rnn_type='elman', output_state='last'):\n",
    "    super().__init__()\n",
    "    types = {'elman': nn.RNN, 'lstm': nn.LSTM, 'gru': nn.GRU}\n",
    "    states = {\n",
    "        'last': lambda x: x[:,-1],\n",
    "        'avg': lambda x: torch.mean(x, dim=1)}\n",
    "    \n",
    "    try:\n",
    "      self.output_state_fn = states[output_state]\n",
    "    except:\n",
    "      valid_states = list(states.keys())\n",
    "      raise ValueError(f\"wrong type '{output_state}', must be in {valid_states}\")\n",
    "\n",
    "    try:\n",
    "      rec_module = types[rnn_type]\n",
    "    except:\n",
    "      valid_types = list(types.keys())\n",
    "      raise ValueError(f\"wrong type '{rnn_type}', must be in {valid_types}\")\n",
    "    self.rec_module = rec_module(input_size=input_size, hidden_size=hidden_size,\n",
    "                                 bidirectional=True, batch_first=True,\n",
    "                                 num_layers=num_layers)\n",
    "    \n",
    "  def forward(self, x):\n",
    "    output, _ = self.rec_module(x)\n",
    "    return self.output_state_fn(output)\n",
    "\n",
    "class BagOfVectorsEncoder(torch.nn.Module):\n",
    "\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "\n",
    "  def forward(self, x):\n",
    "    # TODO: check if the mean is computed on the right axis\n",
    "    return torch.mean(x, dim=1)\n"
   ],
   "execution_count": 58,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-rpXu4uhqcnH"
   },
   "source": [
    "class FactChecker(torch.nn.Module):\n",
    "\n",
    "  def __init__(self, embedding_matrix, encoder, merger, rnn_type=None, rnn_output=None, rec_size=1, hid_size=50):\n",
    "    \"\"\"\n",
    "      A recurrent network performing Neural Language Inference (Fact Checking).\n",
    "      Params:\n",
    "        embedding_matrix: the embedding matrix for word embedding\n",
    "        encoder: [rnn, mlp, bag], the encoder to compute the sentence embedding\n",
    "        merger: [concatenation, sum, mean], the multi-input merging strategy\n",
    "        RNNEncoder params, only relevant if encoder==rnn:\n",
    "          rnn_type: [elman, lstm, gru], the RNN architecure used in the encoder\n",
    "          rnn_output: [last, avg], the function to compute the sentence encoding from the RNN hidden states\n",
    "          rec_size: int, the number of layers in the rnn\n",
    "          hid_size: int, the hidden size of the rnn\n",
    "\n",
    "    \"\"\"\n",
    "    super().__init__()\n",
    "    self.hid_size = hid_size\n",
    "\n",
    "    # Word embedding\n",
    "    emb_size = embedding_matrix.shape[1]\n",
    "    self.emb_layer = nn.Embedding.from_pretrained(torch.as_tensor(embedding_matrix))\n",
    "\n",
    "    # Sentence embedding\n",
    "    if encoder == 'rnn':\n",
    "      self.encoder = RNNEncoder(emb_size, hid_size, rec_size, rnn_type=rnn_type, output_state=rnn_output)\n",
    "    elif encoder == 'mlp':\n",
    "      pass #TODO: implement\n",
    "    elif encoder == 'bag':\n",
    "      self.encoder = BagOfVectorsEncoder()\n",
    "    else:\n",
    "      raise ValueError(f\"Wrong encoder '{encoder}', must be in ['rnn', 'mlp', 'bag']\")\n",
    "\n",
    "    # Merging\n",
    "    merging_strategies = {\n",
    "        'concatenation': lambda claim, ev: torch.cat((claim, ev), dim=1),\n",
    "        'sum': lambda claim, ev : claim + ev,\n",
    "        'mean': lambda claim, ev : (claim + ev) / 2\n",
    "    }\n",
    "    try:\n",
    "      merging_fn = merging_strategies[merger]\n",
    "    except:\n",
    "      valid_strategies = list(merging_strategies.keys())\n",
    "      raise ValueError(f\"wrong type '{merger}', must be in {valid_strategies}\")\n",
    "    self.merger = merging_fn\n",
    "\n",
    "    # Classifier\n",
    "    self.classifier = get_classifier('classifier', w_in=2*self.hid_size, w_hidden=self.hid_size, w_out=2)\n",
    "\n",
    "  def __call__(self, claim, evidence, debug=False):\n",
    "    # Word embedding\n",
    "    claim = self.emb_layer(claim).float()\n",
    "    evidence = self.emb_layer(evidence).float()\n",
    "    if debug:\n",
    "      print(\"After word embedding\")\n",
    "      print(f\"\\tclaim.shape: {claim.shape}\")\n",
    "      print(f\"\\tevidence.shape: {evidence.shape}\")\n",
    "    # Sentence embedding\n",
    "    claim = self.encoder(claim)\n",
    "    evidence = self.encoder(evidence)\n",
    "    if debug:\n",
    "      print(\"After phrase encoding\")\n",
    "      print(f\"\\tclaim.shape: {claim.shape}\")\n",
    "      print(f\"\\tevidence.shape: {evidence.shape}\")\n",
    "    # Merging\n",
    "    merged_data = self.merger(claim, evidence)\n",
    "    output = self.classifier(merged_data)\n",
    "    if debug:\n",
    "      print(\"After merging\")\n",
    "      print(f\"\\tmerged:data.shape: {merged_data.shape}\")\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "    "
   ],
   "execution_count": 59,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "pPTzVP8MTNx4"
   },
   "source": [
    "model = FactChecker(EMBEDDING_MATRIX, 'rnn', 'concatenation', rnn_type='elman', rnn_output='last', rec_size=1, hid_size=50)"
   ],
   "execution_count": 63,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8Nf8wiFgU_h0",
    "outputId": "09a76fdc-6231-4575-9afe-3f5283b47b1d"
   },
   "source": [
    "claim = torch.randint(2000, (10,20))\n",
    "evidence = torch.randint(2000, (10,20))\n",
    "print(model(claim, evidence, debug=True).shape)\n"
   ],
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After word embedding\n",
      "\tclaim.shape: torch.Size([10, 20, 100])\n",
      "\tevidence.shape: torch.Size([10, 20, 100])\n",
      "After phrase encoding\n",
      "\tclaim.shape: torch.Size([10, 100])\n",
      "\tevidence.shape: torch.Size([10, 100])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (10x200 and 100x50)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_7772/2864581136.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[0mclaim\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrandint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m2000\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m(\u001B[0m\u001B[1;36m10\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;36m20\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[0mevidence\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrandint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m2000\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m(\u001B[0m\u001B[1;36m10\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;36m20\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mclaim\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mevidence\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdebug\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      4\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_7772/1195071034.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, claim, evidence, debug)\u001B[0m\n\u001B[0;32m     65\u001B[0m     \u001B[1;31m# Merging\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     66\u001B[0m     \u001B[0mmerged_data\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmerger\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mclaim\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mevidence\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 67\u001B[1;33m     \u001B[0moutput\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mclassifier\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmerged_data\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     68\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mdebug\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     69\u001B[0m       \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"After merging\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\pietr\\pycharmprojects\\assignment_two\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1100\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1101\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1102\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1103\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1104\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\pietr\\pycharmprojects\\assignment_two\\venv\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    139\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    140\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mmodule\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 141\u001B[1;33m             \u001B[0minput\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodule\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    142\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0minput\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    143\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\pietr\\pycharmprojects\\assignment_two\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1100\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1101\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1102\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1103\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1104\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\pietr\\pycharmprojects\\assignment_two\\venv\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    101\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    102\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mTensor\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m->\u001B[0m \u001B[0mTensor\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 103\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mF\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlinear\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mweight\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbias\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    104\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    105\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mextra_repr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m->\u001B[0m \u001B[0mstr\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\pietr\\pycharmprojects\\assignment_two\\venv\\lib\\site-packages\\torch\\nn\\functional.py\u001B[0m in \u001B[0;36mlinear\u001B[1;34m(input, weight, bias)\u001B[0m\n\u001B[0;32m   1846\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mhas_torch_function_variadic\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mweight\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbias\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1847\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mhandle_torch_function\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlinear\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mweight\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbias\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mweight\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbias\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mbias\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1848\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_C\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_nn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlinear\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mweight\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbias\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1849\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1850\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: mat1 and mat2 shapes cannot be multiplied (10x200 and 100x50)"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_GDv0pqw3UsB"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "OWtu6Umy3UPr"
   },
   "source": [
    "def training_step(model, optimizer, loss_fn, data_loader, device):\n",
    "  model.train()\n",
    "\n",
    "  for (claim, evidence, label) in data_loader:\n",
    "    #forward\n",
    "    claim = claim.to(device)\n",
    "    evidence = evidence.to(device)\n",
    "    label = label.to(device)\n",
    "    output = model(claim, evidence)\n",
    "    loss = loss_fn(output, target)\n",
    "    loss_value = loss.item()\n",
    "\n",
    "    if not math.isfinite(loss_value):\n",
    "      print(f\"Loss is {loss_value}, stopping training\")\n",
    "      exit(1)\n",
    "\n",
    "    #backward\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()    \n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "em6r40Wq7NWn"
   },
   "source": [
    "def train(optimizer_name, lr, loss_fn, data_loader, device, n_epochs, verbose, batch_size):\n",
    "  '''wandb.login(key=utils.get_wandbkey()) # TODO: implement getter\n",
    "  run = wandb.init(project=\"assignment-two\", entity=\"nlpetroni\", reinit=True, config=cfg_dict)\n",
    "  wandb.define_metric(\"train_step\")\n",
    "  wandb.define_metric(\"epoch\")\n",
    "  wandb.define_metric('train/loss', step_metric=\"train_step\", summary=\"min\")\n",
    "  wandb.define_metric(\"valid/loss\", step_metric=\"epoch\", summary=\"min\")\n",
    "  wandb.define_metric(\"valid/accuracy\", step_metric=\"epoch\", summary=\"max\")'''\n",
    "\n",
    "  train_dl = torch.utils.data.DataLoader(\n",
    "    Dataset(train_set['Claim'], train_set['Evidence'], train_set['Label']),\n",
    "    batch_size=batch_size)\n",
    "  valid_dl = torch.utils.data.DataLoader(\n",
    "    Dataset(val_set['Claim'], val_set['Evidence'], val_set['Label']),\n",
    "    batch_size=batch_size)\n",
    "\n",
    "  model = FactChecker(EMBEDDING_MATRIX, 'rnn', rnn_type='lstm', rnn_output='last')\n",
    "  wandb.watch(model, log_graph=True)\n",
    "  if verbose:\n",
    "    print(summary(model))\n",
    "\n",
    "  if optimizer_name == 'rmsprop':\n",
    "    optimizer = torch.optim.RMSprop(params, lr=cfg.LR, alpha=0.99, momentum=0.5, weight_decay=0)\n",
    "  elif optimizer_name == 'adam':\n",
    "    optimizer = torch.optim.Adam(params, lr=cfg.LR, betas=(0.9, 0.999), weight_decay=0)\n",
    "  else:\n",
    "    raise ValueError(f'wrong optim {optimizer_name}, either rmsprop or adam')\n",
    "\n",
    "  loss = nn.NLLLoss()\n",
    "  train_step = 0\n",
    "  print('STARTING TRAINING')\n",
    "\n",
    "  for epoch in range(n_epochs):\n",
    "    training_step(model, optimizer, loss, train_dl, device)\n",
    "\n",
    "    "
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "vJP2oodB-kS5"
   },
   "source": [
    "v, m = train(0, 0, 0, 0, 0, 0)\n",
    "print(list(m.keys())[0])"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "erLtxDfbGeMV"
   },
   "source": [
    "print(m[-1])"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "CshUGu0OJOrg"
   },
   "source": [
    "inputs = train_set[:]['Evidence'].tolist() + train_set[:]['Claim'].tolist()\n",
    "print(inputs[0])"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ikpf3WelLDGF"
   },
   "source": [
    "glove_voc = utils.get_glove(number_token=False)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "mv1Hc1UuLP1I"
   },
   "source": [
    "list(glove_voc[0].keys())[0]"
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}