{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/NLPetroni/assignment_two/blob/main/solution_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m5ldIOU6KPl4"
   },
   "source": [
    "# Imports and downloads\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zpI5pddAJRU5",
    "outputId": "dabea79b-07c5-45b1-9323-7b925220762e"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "\n",
    "try:\n",
    "  import google.colab\n",
    "  IN_COLAB = True\n",
    "except:\n",
    "  IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "  %cd /content\n",
    "  !rm -rf assignment_two &> /dev/null\n",
    "  !git clone https://github.com/NLPetroni/assignment_two &> /dev/null\n",
    "  %cd assignment_two\n",
    "  sys.path.append(os.getcwd())\n",
    "  !git clone https://gitlab.com/sasso-effe/nlp-assignment-data.git &> /dev/null\n",
    "  !mv nlp-assignment-data/embedding_matrix.npy res/embedding_matrix.npy\n",
    "  !rm -rf nlp-assignment-data\n",
    "  !pip install wandb &> /dev/null\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "o2uzDyzCKrGy"
   },
   "outputs": [],
   "source": [
    "from src import utils\n",
    "import re\n",
    "from functools import reduce\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from typing import List, Callable, Dict\n",
    "import random\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchinfo import summary\n",
    "import math\n",
    "import wandb\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0zr8CGx9JmRN",
    "outputId": "1410490a-4297-40c5-f29f-75b597af7633"
   },
   "outputs": [],
   "source": [
    "utils.download_data('dataset')\n",
    "train_set = pd.read_csv(\"dataset/train_pairs.csv\")\n",
    "val_set = pd.read_csv(\"dataset/val_pairs.csv\")\n",
    "test_set = pd.read_csv(\"dataset/test_pairs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eZ59KJhcJr5I",
    "outputId": "141eb5a9-047f-4da0-8c66-5840f36f3a7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'Claim', 'Evidence', 'ID', 'Label'], dtype='object')\n",
      "Total rows of the train set: 121740\n",
      "Total rows of the validation set: 7165\n",
      "Total rows of the test set: 7189\n"
     ]
    }
   ],
   "source": [
    "print(train_set.columns)\n",
    "print(\"Total rows of the train set: {:d}\".format(len(train_set)))\n",
    "print(\"Total rows of the validation set: {:d}\".format(len(val_set)))\n",
    "print(\"Total rows of the test set: {:d}\".format(len(test_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kTfRZo0zJv16",
    "outputId": "32496989-d94a-45cc-f47b-7d8c653aa392"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "SUPPORTS    89389\nREFUTES     32351\nName: Label, dtype: int64"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yBtVzSl_J0CR"
   },
   "source": [
    "# Dataset pre-processing and conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mps78KxwJ1e6",
    "outputId": "980ed884-dbee-497e-dce2-345a09d938ec"
   },
   "outputs": [],
   "source": [
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;\\t-]')\n",
    "GOOD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "BAD_SYMBOLS_RE = re.compile('(-LRB-)|(-RRB-)|(-LSB-)|(-RSB-)')\n",
    "INSIDE_SQAURE_BRACKETS_RE = re.compile('(-LSB-).*?(-RSB-)')\n",
    "\n",
    "try:\n",
    "    STOPWORDS = set(stopwords.words('english'))\n",
    "except LookupError:\n",
    "    nltk.download('stopwords')\n",
    "    STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def remove_inside_square_brackets(text: str) -> str:\n",
    "    return INSIDE_SQAURE_BRACKETS_RE.sub('', text)\n",
    "\n",
    "def remove_bad_symbols(text: str) -> str:\n",
    "    return BAD_SYMBOLS_RE.sub('', text)\n",
    "\n",
    "def remove_final_tags(text: str) -> str:\n",
    "   return re.sub('\\.\\t.*?$', '', text) \n",
    "\n",
    "def lower(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Transforms given text to lower case.\n",
    "    Example:\n",
    "    Input: 'I really like New York city'\n",
    "    Output: 'i really like new your city'\n",
    "    \"\"\"\n",
    "\n",
    "    return text.lower()\n",
    "\n",
    "def replace_special_characters(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Replaces special characters, such as paranthesis,\n",
    "    with spacing character\n",
    "    \"\"\"\n",
    "\n",
    "    return REPLACE_BY_SPACE_RE.sub(' ', text)\n",
    "\n",
    "def replace_br(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Replaces br characters\n",
    "    \"\"\"\n",
    "\n",
    "    return text.replace('</br>', '')\n",
    "\n",
    "def filter_out_uncommon_symbols(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Removes any special character that is not in the\n",
    "    good symbols list (check regular expression)\n",
    "    \"\"\"\n",
    "\n",
    "    return GOOD_SYMBOLS_RE.sub('', text)\n",
    "\n",
    "def remove_stopwords(text: str) -> str:\n",
    "    return ' '.join([x for x in text.split() if x and x not in STOPWORDS])\n",
    "\n",
    "\n",
    "def strip_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Removes any left or right spacing (including carriage return) from text.\n",
    "    Example:\n",
    "    Input: '  This assignment is cool\\n'\n",
    "    Output: 'This assignment is cool'\n",
    "    \"\"\"\n",
    "\n",
    "    return text.strip()\n",
    "\n",
    "def split_text(text: str) -> List:\n",
    "  return text.split()\n",
    "\n",
    "PREPROCESSING_PIPELINE = [\n",
    "                          remove_inside_square_brackets,\n",
    "                          remove_bad_symbols,\n",
    "                          lower,\n",
    "                          remove_final_tags,\n",
    "                          replace_special_characters,\n",
    "                          filter_out_uncommon_symbols,\n",
    "                          strip_text,\n",
    "                          split_text\n",
    "                          ]\n",
    "\n",
    "# Anchor method\n",
    "\n",
    "def text_prepare(text: str,\n",
    "                 filter_methods: List[Callable[[str], str]] = None) -> str:\n",
    "    \"\"\"\n",
    "    Applies a list of pre-processing functions in sequence (reduce).\n",
    "    Note that the order is important here!\n",
    "    \"\"\"\n",
    "\n",
    "    filter_methods = filter_methods if filter_methods is not None else PREPROCESSING_PIPELINE\n",
    "\n",
    "    return reduce(lambda txt, f: f(txt), filter_methods, text)\n",
    "\n",
    "\n",
    "# In the evidences there is an id at the beginning of the sequence which is\n",
    "# removed with the splice [:1]\n",
    "train_set['Evidence'] = train_set['Evidence'].apply(lambda txt: text_prepare(txt)[1:])\n",
    "train_set['Claim'] = train_set['Claim'].apply(lambda txt: text_prepare(txt))\n",
    "\n",
    "val_set['Evidence'] = val_set['Evidence'].apply(lambda txt: text_prepare(txt)[1:])\n",
    "val_set['Claim'] = val_set['Claim'].apply(lambda txt: text_prepare(txt))\n",
    "\n",
    "test_set['Evidence'] = test_set['Evidence'].apply(lambda txt: text_prepare(txt)[1:])\n",
    "test_set['Claim'] = test_set['Claim'].apply(lambda txt: text_prepare(txt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "kFRnAOuk2Wjb",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ePHzgALO2Wjd",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    \"\"\"Simple dataset class to use dataloaders (batching) \"\"\"\n",
    "    def __init__(self, claims, evidences, labels):\n",
    "        self.claims = claims\n",
    "        self.evidences = evidences\n",
    "        self.labels = torch.tensor(labels, dtype=torch.float)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.claims[idx], self.evidences[idx], self.labels[idx]\n",
    "    def __len__(self):\n",
    "        return self.claims.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "dMzmoTsXf_1_"
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    \"\"\"Used by DataLoader to pad batches\"\"\"\n",
    "    max_claim_len = int(np.quantile([len(claim) for (claim, _, _) in batch], 0.99))\n",
    "    max_evidence_len = int(np.quantile([len(evidence) for (_, evidence, _) in batch], 0.99))\n",
    "    \n",
    "    claims = []\n",
    "    evidences = []\n",
    "    targets = []\n",
    "    for claim, evidence, target in batch:\n",
    "        if len(claim) > max_claim_len:\n",
    "            claims.append(claim[:max_claim_len])\n",
    "        else:\n",
    "            claims.append(([400000] * (max_claim_len - len(claim))) + claim)\n",
    "        if len(evidence) > max_evidence_len:\n",
    "            evidences.append(evidence[:max_evidence_len])\n",
    "        else:\n",
    "            evidences.append(([400000] * (max_evidence_len - len(evidence))) + evidence)\n",
    "          \n",
    "        targets.append(target)\n",
    "\n",
    "    return torch.as_tensor(claims), torch.as_tensor(evidences), torch.as_tensor(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fo02GPAtUBlt"
   },
   "source": [
    "## Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gbq8J24TXLdm",
    "outputId": "99a7b79a-d6cb-4931-b0d8-cb306c79cb0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vocabulary and the embedding matrix are already present. Loading them...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "if (os.path.exists(\"res/vocabulary.pkl\") and os.path.exists(\"res/embedding_matrix.npy\")):\n",
    "  print('The vocabulary and the embedding matrix are already present. Loading them...')\n",
    "  with open('res/vocabulary.pkl', 'rb') as f:\n",
    "    vocabulary = pickle.load(f)\n",
    "  embedding_matrix = np.load(\"res/embedding_matrix.npy\", )\n",
    "  print(\"Done!\")\n",
    "  \n",
    "else:\n",
    "  print(\"The vocabulary and the embedding matrix are NOT present. Creating them...\")\n",
    "  glove_voc, embedding_matrix = utils.get_glove(number_token=False)\n",
    "  voc_evidence_train = [item for sublist in train_set[:]['Evidence'] for item in sublist]\n",
    "  voc_claim_train = [item for sublist in train_set[:]['Claim'] for item in sublist]\n",
    "  TRAIN_VOC = set(voc_evidence_train + voc_claim_train)\n",
    "  voc_evidence_val = [item for sublist in val_set[:]['Evidence'] for item in sublist]\n",
    "  voc_claim_val = [item for sublist in val_set[:]['Claim'] for item in sublist]\n",
    "  VAL_VOC = set(voc_evidence_val + voc_claim_val)\n",
    "\n",
    "  inputs = train_set[:]['Evidence'].tolist() + train_set[:]['Claim'].tolist()\n",
    "  vocabulary, embedding_matrix = utils.add_oov(glove_voc, TRAIN_VOC, embedding_matrix, inputs)\n",
    "  inputs = val_set[:]['Evidence'].tolist() + val_set[:]['Claim'].tolist()\n",
    "  vocabulary, embedding_matrix = utils.add_oov(vocabulary, VAL_VOC, embedding_matrix, inputs)\n",
    "\n",
    "  with open(\"res/vocabulary.pkl\", \"wb\") as file:\n",
    "    pickle.dump(vocabulary, file)\n",
    "  np.save(\"res/embedding_matrix.npy\", embedding_matrix)\n",
    "  print(\"Vocabulary and embedding matrix created! Remember to download the generated files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "--zNevYb2Wjg",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "W7Li-ZY72Wjh",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "voc_key_list = list(vocabulary.keys())\n",
    "voc_val_list = list(vocabulary.values())\n",
    "\n",
    "def tokenize(input: List) -> torch.Tensor:\n",
    "  result = list(map(lambda x: vocabulary[x], input))\n",
    "  return result\n",
    "\n",
    "def detokenize(input: torch.Tensor) -> List:\n",
    "  result = input.tolist()\n",
    "  result = list(map(lambda x: voc_key_list[voc_val_list.index(x)], result))\n",
    "  return result\n",
    "\n",
    "# tokenize training set\n",
    "train_set['Evidence'] = train_set['Evidence'].map(tokenize)\n",
    "train_set['Claim'] = train_set['Claim'].map(tokenize)\n",
    "train_set['Label'] = train_set['Label'].map(lambda x: float(1.0) if x == 'SUPPORTS' else float(0.0))\n",
    "\n",
    "# tokenize validation set\n",
    "val_set['Evidence'] = val_set['Evidence'].map(tokenize)\n",
    "val_set['Claim'] = val_set['Claim'].map(tokenize)\n",
    "val_set['Label'] = val_set['Label'].map(lambda x: float(1.0) if x == 'SUPPORTS' else float(0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "84ym75Vh2Wjh"
   },
   "source": [
    "# Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "J0Hk8G5NcuS4"
   },
   "outputs": [],
   "source": [
    "def get_binary_classifier(name:str,\n",
    "                    w_in: int,\n",
    "                    w_hidden: int,\n",
    "                    n_layers=2\n",
    "                          ) -> nn.Sequential:\n",
    "    \"\"\"Gets a sequential container with a linear+relu+linear classifier\n",
    "\n",
    "    Args:\n",
    "        name: the name prefix to append to each layer in the container.\n",
    "        w_in: the number of the input features.\n",
    "        w_hidden: the number of internal weights\n",
    "\n",
    "    Returns: the created sequential.\n",
    "    \"\"\"\n",
    "    assert n_layers >= 2, f'n_layers is {n_layers}, must be >= 2'\n",
    "    container = nn.Sequential()\n",
    "    container.add_module(f'{name}_fc1', nn.Linear(in_features=w_in, out_features=w_hidden))    \n",
    "    container.add_module(f'{name}_ReLU', nn.ReLU())\n",
    "    for i in range(n_layers-2):\n",
    "      container.add_module(f'{name}_fc{i+2}', nn.Linear(in_features=w_in, out_features=w_in))\n",
    "      container.add_module(f'{name}_ReLU', nn.ReLU())\n",
    "    container.add_module(f'{name}_fc2', nn.Linear(in_features=w_hidden, out_features=1))\n",
    "    return container\n",
    "\n",
    " \n",
    "class RNNEncoder(torch.nn.Module):\n",
    "\n",
    "  def __init__(self, input_size, hidden_size, num_layers, rnn_type='elman', output_state='last', verbose=False):\n",
    "    super().__init__()\n",
    "    if verbose:\n",
    "      print('Initializing RNNEncoder ')\n",
    "    types = {'elman': nn.RNN, 'lstm': nn.LSTM, 'gru': nn.GRU}\n",
    "    states = {\n",
    "        'last': lambda x: x[:,-1],\n",
    "        'avg': lambda x: torch.mean(x, dim=1)}\n",
    "    \n",
    "    try:\n",
    "      self.output_state_fn = states[output_state]\n",
    "    except:\n",
    "      valid_states = list(states.keys())\n",
    "      raise ValueError(f\"wrong type '{output_state}', must be in {valid_states}\")\n",
    "\n",
    "    try:\n",
    "      rec_module = types[rnn_type]\n",
    "    except:\n",
    "      valid_types = list(types.keys())\n",
    "      raise ValueError(f\"wrong type '{rnn_type}', must be in {valid_types}\")\n",
    "    self.rec_module = rec_module(input_size=input_size, hidden_size=hidden_size,\n",
    "                                 bidirectional=True, batch_first=True,\n",
    "                                 num_layers=num_layers)\n",
    "    \n",
    "  def forward(self, x):\n",
    "    output, _ = self.rec_module(x)\n",
    "    return self.output_state_fn(output)\n",
    "\n",
    "class BagOfVectorsEncoder(torch.nn.Module):\n",
    "\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "\n",
    "  def forward(self, x):\n",
    "    # TODO: check if the mean is computed on the right axis\n",
    "    return torch.mean(x, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "-rpXu4uhqcnH"
   },
   "outputs": [],
   "source": [
    "class FactChecker(torch.nn.Module):\n",
    "\n",
    "  def __init__(self, embedding_matrix, encoder, merger, rnn_type=None, rnn_output=None, rec_size=1, hid_size=50, n_layers_classifier=3):\n",
    "    \"\"\"\n",
    "      A recurrent network performing Neural Language Inference (Fact Checking).\n",
    "      Params:\n",
    "        embedding_matrix: the embedding matrix for word embedding\n",
    "        encoder: [rnn, mlp, bag], the encoder to compute the sentence embedding\n",
    "        merger: [concatenation, sum, mean], the multi-input merging strategy\n",
    "        n_layers_classifier: int, the number of layers in the classifier\n",
    "        RNNEncoder params, only relevant if encoder==rnn:\n",
    "          rnn_type: [elman, lstm, gru], the RNN architecure used in the encoder\n",
    "          rnn_output: [last, avg], the function to compute the sentence encoding from the RNN hidden states\n",
    "          rec_size: int, the number of layers in the rnn\n",
    "          hid_size: int, the hidden size of the rnn\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    super().__init__()\n",
    "    self.hid_size = hid_size\n",
    "\n",
    "    # Word embedding\n",
    "    emb_size = embedding_matrix.shape[1]\n",
    "    self.emb_layer = nn.Embedding.from_pretrained(torch.as_tensor(embedding_matrix))\n",
    "\n",
    "    # Sentence embedding\n",
    "    if encoder == 'rnn':\n",
    "      self.encoder = RNNEncoder(emb_size, hid_size, rec_size, rnn_type=rnn_type, output_state=rnn_output)\n",
    "    elif encoder == 'mlp':\n",
    "      pass #TODO: implement\n",
    "    elif encoder == 'bag':\n",
    "      self.encoder = BagOfVectorsEncoder()\n",
    "    else:\n",
    "      raise ValueError(f\"Wrong encoder '{encoder}', must be in ['rnn', 'mlp', 'bag']\")\n",
    "\n",
    "    # Merging\n",
    "    merging_strategies = {\n",
    "        'concatenation': lambda claim, ev: torch.cat((claim, ev), dim=1),\n",
    "        'sum': lambda claim, ev : claim + ev,\n",
    "        'mean': lambda claim, ev : (claim + ev) / 2\n",
    "    }\n",
    "    try:\n",
    "      merging_fn = merging_strategies[merger]\n",
    "    except:\n",
    "      valid_strategies = list(merging_strategies.keys())\n",
    "      raise ValueError(f\"wrong type '{merger}', must be in {valid_strategies}\")\n",
    "    self.merger = merging_fn\n",
    "\n",
    "    # Classifier\n",
    "    classifier_in = self.hid_size * 2 if encoder=='relu' else 100 #TODO implement also the case for mlp\n",
    "    if merger == 'concatenation':\n",
    "      classifier_in *= 2\n",
    "    self.classifier = get_binary_classifier('classifier', w_in=classifier_in, w_hidden=classifier_in//2, n_layers=n_layers_classifier)\n",
    "\n",
    "  def forward(self, claim, evidence, debug=False):\n",
    "    # Word embedding\n",
    "    claim = self.emb_layer(claim).float()\n",
    "    evidence = self.emb_layer(evidence).float()\n",
    "    if debug:\n",
    "      print(\"After word embedding\")\n",
    "      print(f\"\\tclaim.shape: {claim.shape}\")\n",
    "      print(f\"\\tevidence.shape: {evidence.shape}\")\n",
    "    # Sentence embedding\n",
    "    claim = self.encoder(claim)\n",
    "    evidence = self.encoder(evidence)\n",
    "    if debug:\n",
    "      print(\"After phrase encoding\")\n",
    "      print(f\"\\tclaim.shape: {claim.shape}\")\n",
    "      print(f\"\\tevidence.shape: {evidence.shape}\")\n",
    "    # Merging\n",
    "    merged_data = self.merger(claim, evidence)\n",
    "    if debug:\n",
    "      print(\"After merging\")\n",
    "      print(f\"\\tmerged_data.shape: {merged_data.shape}\")\n",
    "    # Classifying\n",
    "    output = self.classifier(merged_data)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_GDv0pqw3UsB"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "OWtu6Umy3UPr"
   },
   "outputs": [],
   "source": [
    "def training_step(model, optimizer, loss_fn, data_loader, device):\n",
    "  model.train()\n",
    "  log_dict = {'train/loss': [], 'train/accuracy': []}\n",
    "\n",
    "  for (claim, evidence, label) in data_loader:\n",
    "    # forward\n",
    "    claim = claim.to(device)\n",
    "    evidence = evidence.to(device)\n",
    "    label = label.to(device)\n",
    "\n",
    "    output = model(claim, evidence)\n",
    "    output = output.view(output.size(0))\n",
    "    loss = loss_fn(output, label)\n",
    "    loss_value = loss.item()\n",
    "\n",
    "    if not math.isfinite(loss_value):\n",
    "      print(f\"Loss is {loss_value}, stopping training\")\n",
    "      exit(1)\n",
    "\n",
    "    # backward\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        preds = torch.sigmoid(output).round()\n",
    "        metric_value = ((label == preds).sum() / (data_loader.batch_size)).item()\n",
    "\n",
    "    log_dict['train/loss'].append(loss_value)\n",
    "    log_dict['train/accuracy'].append(metric_value)\n",
    "\n",
    "  return log_dict\n",
    "\n",
    "\n",
    "def evaluate(model, loss_fn, data_loader, device, metric='accuracy'):\n",
    "  \"\"\"\n",
    "    Evaluate model on the given dataloader.\n",
    "    Parameters:\n",
    "      model: torch.nn.Module to evaluate\n",
    "      loss_fn: torch.nn criterion to use to compute loss, given outputs and targets\n",
    "      data_loader: torch.utils.data.DataLoader\n",
    "      device: torch.device where evaluation is performed\n",
    "      metric: either 'accuracy' or 'f1'\n",
    "    Returns log dict {'valid/loss' : mean loss, 'valid/{metric}': mean metric}\n",
    "  \"\"\"\n",
    "  model.eval()\n",
    "  batch_losses = []\n",
    "  batch_metrics = []\n",
    "  if metric == 'f1':\n",
    "    assert len(data_loader) == 1 # must be a single batch\n",
    "    split = 'test'\n",
    "  else:\n",
    "    split = 'valid'\n",
    "  with torch.no_grad():\n",
    "    for claim, evidence, label in data_loader:\n",
    "      claim = claim.to(device)\n",
    "      evidence = evidence.to(device)\n",
    "      label = label.to(device)\n",
    "\n",
    "      output = model(claim, evidence)\n",
    "      output = output.view(output.size(0))\n",
    "      loss_value = loss_fn(output, label).item()\n",
    "      preds = torch.sigmoid(output).round()\n",
    "\n",
    "      if metric == 'accuracy':\n",
    "        metric_value = ((label == preds).sum() / (data_loader.batch_size)).item()\n",
    "      else:\n",
    "        raise ValueError(f'wrong metric {metric}, must be in [accuracy]')\n",
    "\n",
    "      batch_losses.append(loss_value)\n",
    "      batch_metrics.append(metric_value)\n",
    "\n",
    "  log_dict = {f'{split}/loss': np.mean(batch_losses),\n",
    "             f'{split}/{metric}': np.mean(batch_metrics) if metric == 'accuracy' else batch_metrics[0]}\n",
    "  return log_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "em6r40Wq7NWn"
   },
   "outputs": [],
   "source": [
    "def train(optimizer_name, lr, loss_fn, device, n_epochs, verbose, batch_size, test=False, **model_params):\n",
    "  if len(model_params) == 0:\n",
    "      model_params = {\n",
    "          'encoder': 'rnn',\n",
    "          'merger': 'concatenation',\n",
    "          'rnn_type': 'elman',\n",
    "          'rnn_output': 'last',\n",
    "          'rec_size': 1,\n",
    "          'hid_size': 50\n",
    "      }\n",
    "\n",
    "  cfg_dict = {'epochs': n_epochs, 'batch_size': batch_size, 'optimizer': optimizer_name, 'lr': lr, 'params': model_params}\n",
    "\n",
    "  wandb.login(key='')\n",
    "  run = wandb.init(project=\"assignment-two\", entity=\"nlpetroni\", reinit=True, config=cfg_dict)\n",
    "  wandb.define_metric(\"train_step\")\n",
    "  wandb.define_metric(\"epoch\")\n",
    "  wandb.define_metric('train/loss', step_metric=\"train_step\", summary=\"min\")\n",
    "  wandb.define_metric(\"train/accuracy\", step_metric=\"train_step\", summary=\"max\")\n",
    "  wandb.define_metric(\"valid/loss\", step_metric=\"epoch\", summary=\"min\")\n",
    "  wandb.define_metric(\"valid/accuracy\", step_metric=\"epoch\", summary=\"max\")\n",
    "\n",
    "  train_dl = torch.utils.data.DataLoader(\n",
    "    Dataset(train_set['Claim'], train_set['Evidence'], train_set['Label']),\n",
    "    batch_size=batch_size, collate_fn=collate_fn, shuffle=True)\n",
    "  valid_dl = torch.utils.data.DataLoader(\n",
    "    Dataset(val_set['Claim'], val_set['Evidence'], val_set['Label']),\n",
    "    batch_size=batch_size, collate_fn=collate_fn)\n",
    "\n",
    "  model = FactChecker(embedding_matrix, **model_params)\n",
    "  model.to(device)\n",
    "  wandb.watch(model, log_graph=True)\n",
    "  if verbose:\n",
    "    print(summary(model))\n",
    "\n",
    "  params = [p for p in model.parameters() if p.requires_grad]\n",
    "  if optimizer_name == 'rmsprop':\n",
    "    optimizer = torch.optim.RMSprop(params, lr=lr, alpha=0.99, momentum=0.5, weight_decay=0)\n",
    "  elif optimizer_name == 'adam':\n",
    "    optimizer = torch.optim.Adam(params, lr=lr, betas=(0.9, 0.999), weight_decay=0)\n",
    "  else:\n",
    "    raise ValueError(f'wrong optim {optimizer_name}, either rmsprop or adam')\n",
    "\n",
    "  loss = nn.BCEWithLogitsLoss()\n",
    "  train_step = 0\n",
    "  print('STARTING TRAINING')\n",
    "\n",
    "  for epoch in range(n_epochs):\n",
    "    log_dict = training_step(model, optimizer, loss, train_dl, device)\n",
    "    if not test:\n",
    "      log_dict.update(evaluate(model, loss, valid_dl, device, metric='accuracy'))\n",
    "      for batch_loss in log_dict['train/loss']:\n",
    "        wandb.log({'train_step': train_step, 'epoch': epoch, 'train/loss': batch_loss})\n",
    "        train_step += 1\n",
    "      for batch_accuracy in log_dict['train/accuracy']:\n",
    "        wandb.log({'train/accuracy': batch_accuracy})\n",
    "      wandb.log({'epoch': epoch, 'valid/loss': log_dict['valid/loss'], 'valid/accuracy': log_dict['valid/accuracy']})\n",
    "      print(f'[{epoch:03d}/{n_epochs:03d}] train loss: {np.mean(log_dict[\"train/loss\"]):.3f}, valid loss: {log_dict[\"valid/loss\"]:.3f}, accuracy: {log_dict[\"valid/accuracy\"]:.2f}')\n",
    "  if test:\n",
    "    #log_dict = evaluate(model, loss, test_dl, device, metric=metric)\n",
    "    wandb.log()\n",
    "\n",
    "  run.finish()\n",
    "  return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 524,
     "referenced_widgets": [
      "a67948356223407590687e1cb579679d",
      "ce88d708fd4c4f7ab38843724fb5929c",
      "59c565a1c9b849fc96e0694dd1bb85b9",
      "319a265bf21845ecbf0e3f767d978af4",
      "12d69c8c8bbb41cd8b4eb1e0f3427421",
      "119bf5f05185405daeccab6d8e54044f",
      "c579711f14684da49d47235ef6d773b0",
      "6d945f6c52c6499d90a53405b070c88c"
     ]
    },
    "id": "vJP2oodB-kS5",
    "outputId": "8236bd2b-6004-42c1-ba34-4316e455add2",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mdiegochine\u001B[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                    Syncing run <strong><a href=\"https://wandb.ai/nlpetroni/assignment-two/runs/2kp6eo7i\" target=\"_blank\">celestial-lake-165</a></strong> to <a href=\"https://wandb.ai/nlpetroni/assignment-two\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n\n                "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "FactChecker                              --\n",
      "├─Embedding: 1-1                         (40,320,000)\n",
      "├─RNNEncoder: 1-2                        --\n",
      "│    └─RNN: 2-1                          15,200\n",
      "├─Sequential: 1-3                        --\n",
      "│    └─Linear: 2-2                       20,100\n",
      "│    └─ReLU: 2-3                         --\n",
      "│    └─Linear: 2-4                       101\n",
      "=================================================================\n",
      "Total params: 40,355,401\n",
      "Trainable params: 35,401\n",
      "Non-trainable params: 40,320,000\n",
      "=================================================================\n",
      "STARTING TRAINING\n",
      "[000/020] train loss: 0.591, valid loss: 0.805, accuracy: 0.50\n",
      "[001/020] train loss: 0.563, valid loss: 0.771, accuracy: 0.51\n",
      "[002/020] train loss: 0.518, valid loss: 0.730, accuracy: 0.60\n",
      "[003/020] train loss: 0.492, valid loss: 0.705, accuracy: 0.61\n",
      "[004/020] train loss: 0.479, valid loss: 0.697, accuracy: 0.62\n",
      "[005/020] train loss: 0.469, valid loss: 0.689, accuracy: 0.63\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_11654/3951162048.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0mdevice\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'cuda'\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcuda\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mis_available\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0;34m'cpu'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0mtrain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0moptimizer_name\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'adam'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlr\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0.0001\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mloss_fn\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m''\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdevice\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mn_epochs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m20\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mverbose\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbatch_size\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m512\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/tmp/ipykernel_11654/698666974.py\u001B[0m in \u001B[0;36mtrain\u001B[0;34m(optimizer_name, lr, loss_fn, device, n_epochs, verbose, batch_size, test, **model_params)\u001B[0m\n\u001B[1;32m     47\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     48\u001B[0m   \u001B[0;32mfor\u001B[0m \u001B[0mepoch\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mn_epochs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 49\u001B[0;31m     \u001B[0mlog_dict\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtraining_step\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moptimizer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mloss\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrain_dl\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     50\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mtest\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     51\u001B[0m       \u001B[0mlog_dict\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mevaluate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mloss\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalid_dl\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdevice\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmetric\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'accuracy'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/tmp/ipykernel_11654/2631271123.py\u001B[0m in \u001B[0;36mtraining_step\u001B[0;34m(model, optimizer, loss_fn, data_loader, device)\u001B[0m\n\u001B[1;32m     25\u001B[0m     \u001B[0;32mwith\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mno_grad\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     26\u001B[0m         \u001B[0mpreds\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msigmoid\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0moutput\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mround\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 27\u001B[0;31m         \u001B[0mmetric_value\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlabel\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0mpreds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msum\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m/\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mdata_loader\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbatch_size\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mitem\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     28\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     29\u001B[0m     \u001B[0mlog_dict\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'train/loss'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mloss_value\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "train(optimizer_name='adam', lr=0.0001, loss_fn='', device=device, n_epochs=20, verbose=True, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "z18L9MxcgiE0"
   },
   "outputs": [],
   "source": [
    "def GridSearch(parameters, optimizer_name='adam', loss_fn='', device=None, verbose=True):\n",
    "  for rnn_type in parameters['rnn_type']:\n",
    "    for lr in parameters['lr']:\n",
    "      for batch_size in parameters['batch_size']:\n",
    "        for num_layer_class in parameters['num_layer_class']:\n",
    "          for num_layer_rnn in parameters['num_layer_rnn']:\n",
    "            train(optimizer_name=optimizer_name, lr=lr, loss_fn=loss_fn, device=device, n_epochs=25, verbose=verbose, batch_size=batch_size,\n",
    "                encoder='rnn', merger='concatenation', rnn_type=rnn_type, rnn_output='last', hid_size=50 , n_layers_classifier=num_layer_class, rec_size=num_layer_rnn)\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 559,
     "referenced_widgets": [
      "8d5c1d3479874ed1b7a44706d4c5af8b",
      "efd0b23227c749a29bd63f75e5725ae6",
      "55aa2907adea4fc690c392c332a53c36",
      "5f90cd1a2d8d4d61b129fa6369a2bb1b",
      "eeca154e1882405caadb7b549b2c258e",
      "f915b866069048ea9dd9513377f11f4a",
      "a496e58697994518a7689f734ed5478d",
      "dd951542e0904c1d976ebcfe5c3a15eb"
     ]
    },
    "id": "LdHx5HUdmzKa",
    "outputId": "81a71eea-4242-4063-caa8-83a2f53615db"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mdiegochine\u001B[0m (use `wandb login --relogin` to force relogin)\n",
      "/home/diego/miniconda3/envs/nlp/lib/python3.9/site-packages/IPython/html.py:12: ShimWarning: The `IPython.html` package has been deprecated since IPython 4.0. You should import from `notebook` instead. `IPython.html.widgets` has moved to `ipywidgets`.\n",
      "  warn(\"The `IPython.html` package has been deprecated since IPython 4.0. \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/nlpetroni/assignment-two/runs/3rh105e0\" target=\"_blank\">frosty-dawn-147</a></strong> to <a href=\"https://wandb.ai/nlpetroni/assignment-two\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING TRAINING\n",
      "[000/025] train loss: 0.616, valid loss: 0.811, accuracy: 0.50\n",
      "[001/025] train loss: 0.576, valid loss: 0.794, accuracy: 0.50\n",
      "[002/025] train loss: 0.560, valid loss: 0.772, accuracy: 0.45\n",
      "[003/025] train loss: 0.523, valid loss: 0.745, accuracy: 0.40\n",
      "[004/025] train loss: 0.500, valid loss: 0.706, accuracy: 0.38\n",
      "[005/025] train loss: 0.482, valid loss: 0.701, accuracy: 0.33\n",
      "[006/025] train loss: 0.467, valid loss: 0.680, accuracy: 0.32\n",
      "[007/025] train loss: 0.454, valid loss: 0.668, accuracy: 0.29\n",
      "[008/025] train loss: 0.444, valid loss: 0.650, accuracy: 0.30\n",
      "[009/025] train loss: 0.437, valid loss: 0.636, accuracy: 0.30\n",
      "[010/025] train loss: 0.430, valid loss: 0.636, accuracy: 0.28\n",
      "[011/025] train loss: 0.425, valid loss: 0.619, accuracy: 0.29\n",
      "[012/025] train loss: 0.420, valid loss: 0.623, accuracy: 0.27\n",
      "[013/025] train loss: 0.416, valid loss: 0.624, accuracy: 0.26\n",
      "[014/025] train loss: 0.412, valid loss: 0.618, accuracy: 0.26\n",
      "[015/025] train loss: 0.409, valid loss: 0.611, accuracy: 0.26\n",
      "[016/025] train loss: 0.406, valid loss: 0.617, accuracy: 0.25\n",
      "[017/025] train loss: 0.403, valid loss: 0.622, accuracy: 0.24\n",
      "[018/025] train loss: 0.400, valid loss: 0.585, accuracy: 0.27\n",
      "[019/025] train loss: 0.397, valid loss: 0.632, accuracy: 0.21\n",
      "[020/025] train loss: 0.395, valid loss: 0.599, accuracy: 0.25\n",
      "[021/025] train loss: 0.393, valid loss: 0.617, accuracy: 0.22\n",
      "[022/025] train loss: 0.391, valid loss: 0.578, accuracy: 0.26\n",
      "[023/025] train loss: 0.388, valid loss: 0.593, accuracy: 0.24\n",
      "[024/025] train loss: 0.386, valid loss: 0.617, accuracy: 0.21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 3290... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/accuracy</td><td>▂██▇▇▅▄▄▃▃▃▃▃▃▂▂▂▁▂▁▂▂▁▂▁▂▂▂▂▂▂▁▁▁▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>█▆▇▆▅▅▄▄▅▄▃▃▃▃▃▃▂▃▃▃▂▃▃▂▁▂▂▁▂▂▂▂▁▂▂▂▂▁▁▂</td></tr><tr><td>train_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>valid/accuracy</td><td>██▇▅▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▂▁▂▂▁</td></tr><tr><td>valid/loss</td><td>██▇▆▅▅▄▄▃▃▃▂▂▂▂▂▂▂▁▃▂▂▁▁▂</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>24</td></tr><tr><td>train_step</td><td>2974</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">frosty-dawn-147</strong>: <a href=\"https://wandb.ai/nlpetroni/assignment-two/runs/3rh105e0\" target=\"_blank\">https://wandb.ai/nlpetroni/assignment-two/runs/3rh105e0</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211207_204106-3rh105e0/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/nlpetroni/assignment-two/runs/3tozpjul\" target=\"_blank\">hardy-bird-148</a></strong> to <a href=\"https://wandb.ai/nlpetroni/assignment-two\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING TRAINING\n",
      "[000/025] train loss: 0.620, valid loss: 0.800, accuracy: 0.50\n",
      "[001/025] train loss: 0.578, valid loss: 0.798, accuracy: 0.50\n",
      "[002/025] train loss: 0.558, valid loss: 0.732, accuracy: 0.48\n",
      "[003/025] train loss: 0.506, valid loss: 0.694, accuracy: 0.40\n",
      "[004/025] train loss: 0.478, valid loss: 0.672, accuracy: 0.33\n",
      "[005/025] train loss: 0.460, valid loss: 0.657, accuracy: 0.32\n",
      "[006/025] train loss: 0.446, valid loss: 0.651, accuracy: 0.27\n",
      "[007/025] train loss: 0.435, valid loss: 0.688, accuracy: 0.23\n",
      "[008/025] train loss: 0.427, valid loss: 0.614, accuracy: 0.28\n",
      "[009/025] train loss: 0.420, valid loss: 0.626, accuracy: 0.26\n",
      "[010/025] train loss: 0.414, valid loss: 0.638, accuracy: 0.23\n",
      "[011/025] train loss: 0.409, valid loss: 0.607, accuracy: 0.26\n",
      "[012/025] train loss: 0.405, valid loss: 0.630, accuracy: 0.22\n",
      "[013/025] train loss: 0.401, valid loss: 0.603, accuracy: 0.24\n",
      "[014/025] train loss: 0.398, valid loss: 0.597, accuracy: 0.24\n",
      "[015/025] train loss: 0.394, valid loss: 0.597, accuracy: 0.23\n",
      "[016/025] train loss: 0.391, valid loss: 0.561, accuracy: 0.26\n",
      "[017/025] train loss: 0.388, valid loss: 0.582, accuracy: 0.24\n",
      "[018/025] train loss: 0.385, valid loss: 0.600, accuracy: 0.21\n",
      "[019/025] train loss: 0.383, valid loss: 0.563, accuracy: 0.26\n",
      "[020/025] train loss: 0.380, valid loss: 0.597, accuracy: 0.21\n",
      "[021/025] train loss: 0.378, valid loss: 0.593, accuracy: 0.21\n",
      "[022/025] train loss: 0.377, valid loss: 0.601, accuracy: 0.21\n",
      "[023/025] train loss: 0.375, valid loss: 0.580, accuracy: 0.21\n",
      "[024/025] train loss: 0.373, valid loss: 0.574, accuracy: 0.22\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 3583... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/accuracy</td><td>▂███▇▄▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▂▂▂▁▁▂▁▂▂▂▁▁▁▁</td></tr><tr><td>train/loss</td><td>█▇▇▆▆▅▅▄▄▃▃▃▃▃▃▃▃▃▃▂▂▃▃▂▂▂▃▃▂▃▃▂▂▂▂▂▁▂▂▃</td></tr><tr><td>train_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>valid/accuracy</td><td>██▇▆▄▄▃▁▃▂▂▂▁▂▂▂▂▂▁▂▁▁▁▁▁</td></tr><tr><td>valid/loss</td><td>██▆▅▄▄▄▅▃▃▃▂▃▂▂▂▁▂▂▁▂▂▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>24</td></tr><tr><td>train_step</td><td>2974</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">hardy-bird-148</strong>: <a href=\"https://wandb.ai/nlpetroni/assignment-two/runs/3tozpjul\" target=\"_blank\">https://wandb.ai/nlpetroni/assignment-two/runs/3tozpjul</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211207_204436-3tozpjul/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/nlpetroni/assignment-two/runs/1kwy4btr\" target=\"_blank\">zany-field-149</a></strong> to <a href=\"https://wandb.ai/nlpetroni/assignment-two\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING TRAINING\n",
      "[000/025] train loss: 0.619, valid loss: 0.803, accuracy: 0.50\n",
      "[001/025] train loss: 0.579, valid loss: 0.812, accuracy: 0.50\n",
      "[002/025] train loss: 0.568, valid loss: 0.752, accuracy: 0.50\n",
      "[003/025] train loss: 0.517, valid loss: 0.732, accuracy: 0.35\n",
      "[004/025] train loss: 0.480, valid loss: 0.664, accuracy: 0.35\n",
      "[005/025] train loss: 0.457, valid loss: 0.674, accuracy: 0.30\n",
      "[006/025] train loss: 0.441, valid loss: 0.633, accuracy: 0.30\n",
      "[007/025] train loss: 0.430, valid loss: 0.619, accuracy: 0.31\n",
      "[008/025] train loss: 0.421, valid loss: 0.638, accuracy: 0.25\n",
      "[009/025] train loss: 0.414, valid loss: 0.615, accuracy: 0.27\n",
      "[010/025] train loss: 0.408, valid loss: 0.608, accuracy: 0.26\n",
      "[011/025] train loss: 0.403, valid loss: 0.592, accuracy: 0.26\n",
      "[012/025] train loss: 0.400, valid loss: 0.595, accuracy: 0.25\n",
      "[013/025] train loss: 0.395, valid loss: 0.600, accuracy: 0.25\n",
      "[014/025] train loss: 0.393, valid loss: 0.635, accuracy: 0.20\n",
      "[015/025] train loss: 0.389, valid loss: 0.601, accuracy: 0.23\n",
      "[016/025] train loss: 0.387, valid loss: 0.596, accuracy: 0.22\n",
      "[017/025] train loss: 0.386, valid loss: 0.568, accuracy: 0.24\n",
      "[018/025] train loss: 0.382, valid loss: 0.592, accuracy: 0.22\n",
      "[019/025] train loss: 0.379, valid loss: 0.602, accuracy: 0.20\n",
      "[020/025] train loss: 0.378, valid loss: 0.583, accuracy: 0.22\n",
      "[021/025] train loss: 0.375, valid loss: 0.584, accuracy: 0.21\n",
      "[022/025] train loss: 0.373, valid loss: 0.562, accuracy: 0.22\n",
      "[023/025] train loss: 0.372, valid loss: 0.569, accuracy: 0.22\n",
      "[024/025] train loss: 0.370, valid loss: 0.593, accuracy: 0.19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 3709... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/accuracy</td><td>▂████▄▄▃▃▂▃▂▂▃▂▂▃▂▂▂▂▁▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▂▂▁</td></tr><tr><td>train/loss</td><td>█▆▇▆▅▅▅▄▃▃▃▃▃▃▃▂▂▃▂▂▂▂▁▂▂▂▂▁▂▁▂▂▂▃▂▂▂▂▂▃</td></tr><tr><td>train_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>valid/accuracy</td><td>███▅▅▃▃▄▂▃▂▃▂▂▁▂▂▂▂▁▂▁▂▂▁</td></tr><tr><td>valid/loss</td><td>██▆▆▄▄▃▃▃▂▂▂▂▂▃▂▂▁▂▂▂▂▁▁▂</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>24</td></tr><tr><td>train_step</td><td>2974</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">zany-field-149</strong>: <a href=\"https://wandb.ai/nlpetroni/assignment-two/runs/1kwy4btr\" target=\"_blank\">https://wandb.ai/nlpetroni/assignment-two/runs/1kwy4btr</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211207_205001-1kwy4btr/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/nlpetroni/assignment-two/runs/1smpwbc5\" target=\"_blank\">daily-cherry-150</a></strong> to <a href=\"https://wandb.ai/nlpetroni/assignment-two\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING TRAINING\n",
      "[000/025] train loss: 0.622, valid loss: 0.808, accuracy: 0.50\n",
      "[001/025] train loss: 0.578, valid loss: 0.804, accuracy: 0.50\n",
      "[002/025] train loss: 0.567, valid loss: 0.784, accuracy: 0.47\n",
      "[003/025] train loss: 0.538, valid loss: 0.739, accuracy: 0.46\n",
      "[004/025] train loss: 0.510, valid loss: 0.715, accuracy: 0.41\n",
      "[005/025] train loss: 0.491, valid loss: 0.705, accuracy: 0.36\n",
      "[006/025] train loss: 0.476, valid loss: 0.691, accuracy: 0.32\n",
      "[007/025] train loss: 0.463, valid loss: 0.689, accuracy: 0.29\n",
      "[008/025] train loss: 0.453, valid loss: 0.665, accuracy: 0.29\n",
      "[009/025] train loss: 0.445, valid loss: 0.657, accuracy: 0.29\n",
      "[010/025] train loss: 0.438, valid loss: 0.666, accuracy: 0.27\n",
      "[011/025] train loss: 0.433, valid loss: 0.633, accuracy: 0.29\n",
      "[012/025] train loss: 0.428, valid loss: 0.657, accuracy: 0.25\n",
      "[013/025] train loss: 0.423, valid loss: 0.655, accuracy: 0.24\n",
      "[014/025] train loss: 0.419, valid loss: 0.614, accuracy: 0.27\n",
      "[015/025] train loss: 0.416, valid loss: 0.623, accuracy: 0.26\n",
      "[016/025] train loss: 0.412, valid loss: 0.631, accuracy: 0.25\n",
      "[017/025] train loss: 0.409, valid loss: 0.626, accuracy: 0.24\n",
      "[018/025] train loss: 0.405, valid loss: 0.637, accuracy: 0.22\n",
      "[019/025] train loss: 0.402, valid loss: 0.616, accuracy: 0.25\n",
      "[020/025] train loss: 0.399, valid loss: 0.613, accuracy: 0.23\n",
      "[021/025] train loss: 0.397, valid loss: 0.600, accuracy: 0.25\n",
      "[022/025] train loss: 0.394, valid loss: 0.609, accuracy: 0.24\n",
      "[023/025] train loss: 0.391, valid loss: 0.621, accuracy: 0.22\n",
      "[024/025] train loss: 0.389, valid loss: 0.606, accuracy: 0.23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 3854... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/accuracy</td><td>▂██▇█▆▅▄▃▃▃▂▃▃▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▂▂▂▂▁▁▁▁▁▂▁</td></tr><tr><td>train/loss</td><td>█▅▆▆▅▅▅▄▄▄▄▄▄▃▃▂▂▂▂▃▃▂▂▂▃▂▂▁▂▂▂▁▂▁▂▁▂▁▁▂</td></tr><tr><td>train_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>valid/accuracy</td><td>██▇▇▆▅▄▃▃▃▂▃▂▂▂▂▂▂▁▂▁▂▁▁▁</td></tr><tr><td>valid/loss</td><td>██▇▆▅▅▄▄▃▃▃▂▃▃▁▂▂▂▂▂▁▁▁▂▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>24</td></tr><tr><td>train_step</td><td>2974</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">daily-cherry-150</strong>: <a href=\"https://wandb.ai/nlpetroni/assignment-two/runs/1smpwbc5\" target=\"_blank\">https://wandb.ai/nlpetroni/assignment-two/runs/1smpwbc5</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211207_205733-1smpwbc5/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/nlpetroni/assignment-two/runs/olj70tzj\" target=\"_blank\">still-cosmos-151</a></strong> to <a href=\"https://wandb.ai/nlpetroni/assignment-two\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING TRAINING\n",
      "[000/025] train loss: 0.629, valid loss: 0.797, accuracy: 0.50\n",
      "[001/025] train loss: 0.579, valid loss: 0.804, accuracy: 0.50\n",
      "[002/025] train loss: 0.574, valid loss: 0.794, accuracy: 0.50\n",
      "[003/025] train loss: 0.539, valid loss: 0.735, accuracy: 0.42\n",
      "[004/025] train loss: 0.498, valid loss: 0.719, accuracy: 0.34\n",
      "[005/025] train loss: 0.474, valid loss: 0.717, accuracy: 0.28\n",
      "[006/025] train loss: 0.457, valid loss: 0.678, accuracy: 0.28\n",
      "[007/025] train loss: 0.444, valid loss: 0.647, accuracy: 0.29\n",
      "[008/025] train loss: 0.433, valid loss: 0.642, accuracy: 0.28\n",
      "[009/025] train loss: 0.425, valid loss: 0.639, accuracy: 0.26\n",
      "[010/025] train loss: 0.418, valid loss: 0.613, accuracy: 0.26\n",
      "[011/025] train loss: 0.412, valid loss: 0.599, accuracy: 0.26\n",
      "[012/025] train loss: 0.407, valid loss: 0.598, accuracy: 0.26\n",
      "[013/025] train loss: 0.402, valid loss: 0.610, accuracy: 0.24\n",
      "[014/025] train loss: 0.399, valid loss: 0.639, accuracy: 0.21\n",
      "[015/025] train loss: 0.396, valid loss: 0.580, accuracy: 0.25\n",
      "[016/025] train loss: 0.393, valid loss: 0.644, accuracy: 0.20\n",
      "[017/025] train loss: 0.389, valid loss: 0.597, accuracy: 0.23\n",
      "[018/025] train loss: 0.386, valid loss: 0.599, accuracy: 0.23\n",
      "[019/025] train loss: 0.384, valid loss: 0.588, accuracy: 0.23\n",
      "[020/025] train loss: 0.382, valid loss: 0.599, accuracy: 0.22\n",
      "[021/025] train loss: 0.379, valid loss: 0.573, accuracy: 0.24\n",
      "[022/025] train loss: 0.377, valid loss: 0.593, accuracy: 0.21\n",
      "[023/025] train loss: 0.375, valid loss: 0.576, accuracy: 0.23\n",
      "[024/025] train loss: 0.373, valid loss: 0.576, accuracy: 0.23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 3947... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/accuracy</td><td>▂████▇▄▄▃▂▂▃▂▂▂▂▂▂▂▃▂▂▂▂▁▁▂▂▂▂▁▂▂▁▂▂▁▁▁▁</td></tr><tr><td>train/loss</td><td>█▆▅▆▆▅▄▄▄▃▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▃▂▂▁▂▂▂▂▁▂▂▂▂▁▂</td></tr><tr><td>train_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>valid/accuracy</td><td>███▆▄▃▃▃▃▂▂▂▂▂▁▂▁▂▂▂▁▂▁▂▂</td></tr><tr><td>valid/loss</td><td>███▆▅▅▄▃▃▃▂▂▂▂▃▁▃▂▂▁▂▁▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>24</td></tr><tr><td>train_step</td><td>2974</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">still-cosmos-151</strong>: <a href=\"https://wandb.ai/nlpetroni/assignment-two/runs/olj70tzj\" target=\"_blank\">https://wandb.ai/nlpetroni/assignment-two/runs/olj70tzj</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211207_210056-olj70tzj/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/nlpetroni/assignment-two/runs/2bizvnvd\" target=\"_blank\">stellar-armadillo-152</a></strong> to <a href=\"https://wandb.ai/nlpetroni/assignment-two\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING TRAINING\n",
      "[000/025] train loss: 0.618, valid loss: 0.807, accuracy: 0.50\n",
      "[001/025] train loss: 0.579, valid loss: 0.816, accuracy: 0.50\n",
      "[002/025] train loss: 0.568, valid loss: 0.767, accuracy: 0.44\n",
      "[003/025] train loss: 0.515, valid loss: 0.698, accuracy: 0.39\n",
      "[004/025] train loss: 0.481, valid loss: 0.678, accuracy: 0.33\n",
      "[005/025] train loss: 0.459, valid loss: 0.666, accuracy: 0.30\n",
      "[006/025] train loss: 0.442, valid loss: 0.655, accuracy: 0.28\n",
      "[007/025] train loss: 0.433, valid loss: 0.641, accuracy: 0.26\n",
      "[008/025] train loss: 0.422, valid loss: 0.628, accuracy: 0.26\n",
      "[009/025] train loss: 0.417, valid loss: 0.657, accuracy: 0.23\n",
      "[010/025] train loss: 0.411, valid loss: 0.617, accuracy: 0.24\n",
      "[011/025] train loss: 0.405, valid loss: 0.632, accuracy: 0.21\n",
      "[012/025] train loss: 0.401, valid loss: 0.590, accuracy: 0.25\n",
      "[013/025] train loss: 0.399, valid loss: 0.622, accuracy: 0.21\n",
      "[014/025] train loss: 0.395, valid loss: 0.570, accuracy: 0.28\n",
      "[015/025] train loss: 0.392, valid loss: 0.597, accuracy: 0.23\n",
      "[016/025] train loss: 0.389, valid loss: 0.603, accuracy: 0.22\n",
      "[017/025] train loss: 0.387, valid loss: 0.636, accuracy: 0.18\n",
      "[018/025] train loss: 0.384, valid loss: 0.616, accuracy: 0.20\n",
      "[019/025] train loss: 0.382, valid loss: 0.589, accuracy: 0.23\n",
      "[020/025] train loss: 0.380, valid loss: 0.608, accuracy: 0.20\n",
      "[021/025] train loss: 0.379, valid loss: 0.585, accuracy: 0.22\n",
      "[022/025] train loss: 0.376, valid loss: 0.593, accuracy: 0.21\n",
      "[023/025] train loss: 0.375, valid loss: 0.624, accuracy: 0.18\n",
      "[024/025] train loss: 0.373, valid loss: 0.573, accuracy: 0.23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 4281... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/accuracy</td><td>▂███▇▅▄▃▃▂▂▂▂▂▂▂▂▂▃▂▂▂▂▂▁▂▂▂▂▁▂▁▂▂▁▁▁▁▁▁</td></tr><tr><td>train/loss</td><td>█▆▇▇▇▅▄▅▄▃▃▃▃▃▃▃▃▃▂▂▃▂▂▁▃▂▁▂▃▂▂▂▂▂▂▁▂▂▂▁</td></tr><tr><td>train_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>valid/accuracy</td><td>██▇▆▄▃▃▃▃▂▂▂▃▂▃▂▂▁▁▂▁▂▂▁▂</td></tr><tr><td>valid/loss</td><td>██▇▅▄▄▃▃▃▃▂▃▂▂▁▂▂▃▂▂▂▁▂▃▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>24</td></tr><tr><td>train_step</td><td>2974</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">stellar-armadillo-152</strong>: <a href=\"https://wandb.ai/nlpetroni/assignment-two/runs/2bizvnvd\" target=\"_blank\">https://wandb.ai/nlpetroni/assignment-two/runs/2bizvnvd</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211207_210627-2bizvnvd/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/nlpetroni/assignment-two/runs/2z8b857f\" target=\"_blank\">fluent-donkey-153</a></strong> to <a href=\"https://wandb.ai/nlpetroni/assignment-two\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING TRAINING\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1024x1 and 200x200)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_3042/1314713514.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0mdevice\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'cuda'\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcuda\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mis_available\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0;34m'cpu'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 4\u001B[0;31m \u001B[0mGridSearch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mparameters\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moptimizer_name\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'adam'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mloss_fn\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m''\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdevice\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mverbose\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/tmp/ipykernel_3042/1629368454.py\u001B[0m in \u001B[0;36mGridSearch\u001B[0;34m(parameters, optimizer_name, loss_fn, device, verbose)\u001B[0m\n\u001B[1;32m      5\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mnum_layer_class\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mparameters\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'num_layer_class'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m           \u001B[0;32mfor\u001B[0m \u001B[0mnum_layer_rnn\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mparameters\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'num_layer_rnn'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 7\u001B[0;31m             train(optimizer_name=optimizer_name, lr=lr, loss_fn=loss_fn, device=device, n_epochs=25, verbose=verbose, batch_size=batch_size,\n\u001B[0m\u001B[1;32m      8\u001B[0m                 encoder='rnn', merger='concatenation', rnn_type=rnn_type, rnn_output='last', hid_size=50 , n_layers_classifier=num_layer_class, rec_size=num_layer_rnn)\n\u001B[1;32m      9\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/tmp/ipykernel_3042/4155411453.py\u001B[0m in \u001B[0;36mtrain\u001B[0;34m(optimizer_name, lr, loss_fn, device, n_epochs, verbose, batch_size, test, **model_params)\u001B[0m\n\u001B[1;32m     47\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     48\u001B[0m   \u001B[0;32mfor\u001B[0m \u001B[0mepoch\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mn_epochs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 49\u001B[0;31m     \u001B[0mlog_dict\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtraining_step\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moptimizer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mloss\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrain_dl\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     50\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mtest\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     51\u001B[0m       \u001B[0mlog_dict\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mevaluate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mloss\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalid_dl\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdevice\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmetric\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'accuracy'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/tmp/ipykernel_3042/2498190115.py\u001B[0m in \u001B[0;36mtraining_step\u001B[0;34m(model, optimizer, loss_fn, data_loader, device)\u001B[0m\n\u001B[1;32m      9\u001B[0m       \u001B[0mevidence\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mevidence\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     10\u001B[0m       \u001B[0mlabel\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlabel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 11\u001B[0;31m     \u001B[0moutput\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mclaim\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mevidence\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     12\u001B[0m     \u001B[0moutput\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0moutput\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mview\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0moutput\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msize\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/nlp/lib/python3.9/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1100\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1101\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1102\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1103\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1104\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/tmp/ipykernel_3042/2677808757.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, claim, evidence, debug)\u001B[0m\n\u001B[1;32m     74\u001B[0m       \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf\"\\tmerged_data.shape: {merged_data.shape}\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     75\u001B[0m     \u001B[0;31m# Classifying\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 76\u001B[0;31m     \u001B[0moutput\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mclassifier\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmerged_data\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     77\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0moutput\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/nlp/lib/python3.9/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1100\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1101\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1102\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1103\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1104\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/nlp/lib/python3.9/site-packages/torch/nn/modules/container.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    139\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    140\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mmodule\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 141\u001B[0;31m             \u001B[0minput\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodule\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    142\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    143\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/nlp/lib/python3.9/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1118\u001B[0m             \u001B[0minput\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mbw_hook\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msetup_input_hook\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1119\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1120\u001B[0;31m         \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1121\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0m_global_forward_hooks\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_forward_hooks\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1122\u001B[0m             \u001B[0;32mfor\u001B[0m \u001B[0mhook\u001B[0m \u001B[0;32min\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0m_global_forward_hooks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_forward_hooks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/nlp/lib/python3.9/site-packages/torch/nn/modules/linear.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    101\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    102\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mTensor\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mTensor\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 103\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mF\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlinear\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mweight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbias\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    104\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    105\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mextra_repr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/nlp/lib/python3.9/site-packages/torch/nn/functional.py\u001B[0m in \u001B[0;36mlinear\u001B[0;34m(input, weight, bias)\u001B[0m\n\u001B[1;32m   1846\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mhas_torch_function_variadic\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mweight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbias\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1847\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mhandle_torch_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlinear\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mweight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbias\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mweight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbias\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mbias\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1848\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_C\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_nn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlinear\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mweight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbias\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1849\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1850\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: mat1 and mat2 shapes cannot be multiplied (1024x1 and 200x200)"
     ]
    }
   ],
   "source": [
    "parameters = {'rnn_type': ['lstm', 'gru'], 'lr': [1e-4, 1e-5], 'batch_size': [1024, 512], 'num_layer_class':[2, 3, 4], 'num_layer_rnn':[1, 2, 3]}\n",
    "GridSearch(parameters, optimizer_name='adam', loss_fn='', device=device, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "solution_2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "119bf5f05185405daeccab6d8e54044f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "12d69c8c8bbb41cd8b4eb1e0f3427421": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "319a265bf21845ecbf0e3f767d978af4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6d945f6c52c6499d90a53405b070c88c",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c579711f14684da49d47235ef6d773b0",
      "value": 1
     }
    },
    "55aa2907adea4fc690c392c332a53c36": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f915b866069048ea9dd9513377f11f4a",
      "placeholder": "​",
      "style": "IPY_MODEL_eeca154e1882405caadb7b549b2c258e",
      "value": " 0.01MB of 0.01MB uploaded (0.00MB deduped)\r"
     }
    },
    "59c565a1c9b849fc96e0694dd1bb85b9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_119bf5f05185405daeccab6d8e54044f",
      "placeholder": "​",
      "style": "IPY_MODEL_12d69c8c8bbb41cd8b4eb1e0f3427421",
      "value": " 0.01MB of 0.01MB uploaded (0.00MB deduped)\r"
     }
    },
    "5f90cd1a2d8d4d61b129fa6369a2bb1b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dd951542e0904c1d976ebcfe5c3a15eb",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a496e58697994518a7689f734ed5478d",
      "value": 1
     }
    },
    "6d945f6c52c6499d90a53405b070c88c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8d5c1d3479874ed1b7a44706d4c5af8b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_55aa2907adea4fc690c392c332a53c36",
       "IPY_MODEL_5f90cd1a2d8d4d61b129fa6369a2bb1b"
      ],
      "layout": "IPY_MODEL_efd0b23227c749a29bd63f75e5725ae6"
     }
    },
    "a496e58697994518a7689f734ed5478d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a67948356223407590687e1cb579679d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_59c565a1c9b849fc96e0694dd1bb85b9",
       "IPY_MODEL_319a265bf21845ecbf0e3f767d978af4"
      ],
      "layout": "IPY_MODEL_ce88d708fd4c4f7ab38843724fb5929c"
     }
    },
    "c579711f14684da49d47235ef6d773b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ce88d708fd4c4f7ab38843724fb5929c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dd951542e0904c1d976ebcfe5c3a15eb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eeca154e1882405caadb7b549b2c258e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "efd0b23227c749a29bd63f75e5725ae6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f915b866069048ea9dd9513377f11f4a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}